{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to DART DART is the Digital Archivist's Resource Tool. It provides both a GUI and a command-line interface for packaging files and uploading them to remote repositories. Supported Operations The initial release of DART 2.0 supports the following features: Creating BagIt bags that conform to defined BagIt profiles Validating BagIt bags according to defined BagIt profiles Uploading bags and other files to remote S3 endpoints Creating and modifying BagIt profiles through a visual point-and-click editor Defining repeatable Workflows for bagging and uploading files Running multiple simultaneous bagging and upload jobs Read-only integration with the APTrust's REST API to display the status of ingested materials and pending work items A command-line tool to enable scriptable bagging and upload operations To start using DART, see our Getting Started page. Plugin Architecture Most of DART's features are implemented in plugins, which enable developers to add new features without having to understand all of DART's internals. DART is an open source project of the Academic Preservation Trust, which encourages developers to contribute new plugins to extend the tool's functionality. DART 2.0 supports the following types of plugins: Format Readers - These allow DART to read files packaged in various formats, such as tar, zip, rar, parchive, OCFL, etc. Currently supported in formats in version 2.0: directory/file system tar Format Writers - These allow DART to write files in various formats, such as tar, zip, rar, parchive, OCFL, etc. Currently supported in formats in version 2.0: directory/file system tar Network Clients - These allow DART to send and retrieve files across a network. DART 2.0 supports the following protocols: S3 Repository Clients - These allow DART to interact with remote repositories. Currently supported: APTrust Setup Modules - These allow organizations to install default settings and create a list of simple questions to get local users up and running quickly. Currently supported: APTrust DPN Writing DART plugins requires a working knowledge of JavaScript and HTML. If you're interested in developing DART plugins, see our Developers page and our full API documentation . Useful Links Getting Started with DART Developing DART Plugins DART API documentation DART source code on GitHub Credits Brace yourselves gentlemen. According to the gas chromatograph, the secret ingredient is... Love!? Who's been screwing with this thing?","title":"Home"},{"location":"#welcome-to-dart","text":"DART is the Digital Archivist's Resource Tool. It provides both a GUI and a command-line interface for packaging files and uploading them to remote repositories.","title":"Welcome to DART"},{"location":"#supported-operations","text":"The initial release of DART 2.0 supports the following features: Creating BagIt bags that conform to defined BagIt profiles Validating BagIt bags according to defined BagIt profiles Uploading bags and other files to remote S3 endpoints Creating and modifying BagIt profiles through a visual point-and-click editor Defining repeatable Workflows for bagging and uploading files Running multiple simultaneous bagging and upload jobs Read-only integration with the APTrust's REST API to display the status of ingested materials and pending work items A command-line tool to enable scriptable bagging and upload operations To start using DART, see our Getting Started page.","title":"Supported Operations"},{"location":"#plugin-architecture","text":"Most of DART's features are implemented in plugins, which enable developers to add new features without having to understand all of DART's internals. DART is an open source project of the Academic Preservation Trust, which encourages developers to contribute new plugins to extend the tool's functionality. DART 2.0 supports the following types of plugins: Format Readers - These allow DART to read files packaged in various formats, such as tar, zip, rar, parchive, OCFL, etc. Currently supported in formats in version 2.0: directory/file system tar Format Writers - These allow DART to write files in various formats, such as tar, zip, rar, parchive, OCFL, etc. Currently supported in formats in version 2.0: directory/file system tar Network Clients - These allow DART to send and retrieve files across a network. DART 2.0 supports the following protocols: S3 Repository Clients - These allow DART to interact with remote repositories. Currently supported: APTrust Setup Modules - These allow organizations to install default settings and create a list of simple questions to get local users up and running quickly. Currently supported: APTrust DPN Writing DART plugins requires a working knowledge of JavaScript and HTML. If you're interested in developing DART plugins, see our Developers page and our full API documentation .","title":"Plugin Architecture"},{"location":"#useful-links","text":"Getting Started with DART Developing DART Plugins DART API documentation DART source code on GitHub","title":"Useful Links"},{"location":"#credits","text":"Brace yourselves gentlemen. According to the gas chromatograph, the secret ingredient is... Love!? Who's been screwing with this thing?","title":"Credits"},{"location":"developers/","text":"Developer's Guide to DART DART's primary purpose is to pack and ship digital materials for preservation. It includes a GUI for non-technical users who want to drag and drop file, and a command line interface for more technical users who want to script DART jobs . While DART's initial release supports the BagIt packaging format and uploads to S3-compatible services, future users may require additional package formats such as rar, parchive, OCFL, etc. They may also need to ship files using network protocols such as SFTP, rsync, scp and others. DART has a plugin architecture that allows developers to contribute code that will add these package formats and network protocols. If you know how to write JavaScript, you can contribute plugins without having to understand DART's internals. Getting the Code To get started developing DART plugins, download the souce from GitHub. git clone git @github . com : APTrust / dart . git Once you have the source, you'll need to install the dependencies. Change into the dart directory and run this: npm install To ensure all is working, run the tests. npm test -- --runInBand Useful Links Writing Plugins for DART Building DART Installers DART API Documentation DART source on GitHub","title":"Developer's Guide to DART"},{"location":"developers/#developers-guide-to-dart","text":"DART's primary purpose is to pack and ship digital materials for preservation. It includes a GUI for non-technical users who want to drag and drop file, and a command line interface for more technical users who want to script DART jobs . While DART's initial release supports the BagIt packaging format and uploads to S3-compatible services, future users may require additional package formats such as rar, parchive, OCFL, etc. They may also need to ship files using network protocols such as SFTP, rsync, scp and others. DART has a plugin architecture that allows developers to contribute code that will add these package formats and network protocols. If you know how to write JavaScript, you can contribute plugins without having to understand DART's internals.","title":"Developer's Guide to DART"},{"location":"developers/#getting-the-code","text":"To get started developing DART plugins, download the souce from GitHub. git clone git @github . com : APTrust / dart . git Once you have the source, you'll need to install the dependencies. Change into the dart directory and run this: npm install To ensure all is working, run the tests. npm test -- --runInBand","title":"Getting the Code"},{"location":"developers/#useful-links","text":"Writing Plugins for DART Building DART Installers DART API Documentation DART source on GitHub","title":"Useful Links"},{"location":"developers/architecture/","text":"Architecture DART was designed around a few core principles. It should use commonly available and well understood open source technologies. It should run on Windows, Mac, and Linux. It should include a plugin architecture so developers can add new features and functions without having to learn the system's internals. It should separate core functional code from UI code, so the application's core features can be run from the UI or from the command line. Components should be as loosely coupled as possible so that: They can be replaced at will, and so They don't cause bugs in other components. All components should be implemented in the simplest way possible. This means: Don't add extraneous JavaScript libraries just to pick up one or two handy functions. Don't do in JavaScript what the browser already does for you (such as navigation and making decisions about rendering). Don't use libraries like React, Angular, Vue, etc. (because DART's HTML is so simple, these libraries would only add complexity without adding value). DART should be maintainable for the long term. In practice, this goes beyond architectural principles to include two ongoing practices to accompany all new and updated code: Thorough testing. Complete and useful documentation. Tech Stack DART is built on the following tech stack: Electron , which provides a cross-platform UI as well as build and distribution capabilities. Node.js , which provides a portable JavaScript runtime and a set of core libraries. HTML5 , which provides simple interactive displays. Bootstrap 4 , which provides a rich and flexible CSS framework. Handlebars , a brain-dead templating language that forces you to separate logic from presentation. MVC Pattern DART uses an MVC design pattern similar to Ruby on Rails. This choice was guided by the following considerations: DART can route requests using standard URLs. There's no need for a routing engine, or for JavaScript to keep track of navigation history, the state of HTML components on the page, data mappings, a virtual DOM, etc. Each MVC request routes to one endpoint of one controller and the mapping is always obvious from the URL. For example, AppSetting/list maps to the list() method of the AppSetting controller. All request parameters are passed through the URL, so there's no need for special JavaScript classes, structures, or mappings. Each request results in a full re-rendering of the DOM. This is seen as an evil to be avoided in web applications because a page load requires one or more network calls and causes the user to lose state information and the dynamically loaded content that comes from infinite scrolling. DART does not need to make network calls to load pages, and because it keeps no state, there's nothing to lose. Because a typical DART page loads only 10-20 kilobytes of HTML, it renders quickly, taking advantage of all the browser's rendering optimizations.","title":"Architecture"},{"location":"developers/architecture/#architecture","text":"DART was designed around a few core principles. It should use commonly available and well understood open source technologies. It should run on Windows, Mac, and Linux. It should include a plugin architecture so developers can add new features and functions without having to learn the system's internals. It should separate core functional code from UI code, so the application's core features can be run from the UI or from the command line. Components should be as loosely coupled as possible so that: They can be replaced at will, and so They don't cause bugs in other components. All components should be implemented in the simplest way possible. This means: Don't add extraneous JavaScript libraries just to pick up one or two handy functions. Don't do in JavaScript what the browser already does for you (such as navigation and making decisions about rendering). Don't use libraries like React, Angular, Vue, etc. (because DART's HTML is so simple, these libraries would only add complexity without adding value). DART should be maintainable for the long term. In practice, this goes beyond architectural principles to include two ongoing practices to accompany all new and updated code: Thorough testing. Complete and useful documentation.","title":"Architecture"},{"location":"developers/architecture/#tech-stack","text":"DART is built on the following tech stack: Electron , which provides a cross-platform UI as well as build and distribution capabilities. Node.js , which provides a portable JavaScript runtime and a set of core libraries. HTML5 , which provides simple interactive displays. Bootstrap 4 , which provides a rich and flexible CSS framework. Handlebars , a brain-dead templating language that forces you to separate logic from presentation.","title":"Tech Stack"},{"location":"developers/architecture/#mvc-pattern","text":"DART uses an MVC design pattern similar to Ruby on Rails. This choice was guided by the following considerations: DART can route requests using standard URLs. There's no need for a routing engine, or for JavaScript to keep track of navigation history, the state of HTML components on the page, data mappings, a virtual DOM, etc. Each MVC request routes to one endpoint of one controller and the mapping is always obvious from the URL. For example, AppSetting/list maps to the list() method of the AppSetting controller. All request parameters are passed through the URL, so there's no need for special JavaScript classes, structures, or mappings. Each request results in a full re-rendering of the DOM. This is seen as an evil to be avoided in web applications because a page load requires one or more network calls and causes the user to lose state information and the dynamically loaded content that comes from infinite scrolling. DART does not need to make network calls to load pages, and because it keeps no state, there's nothing to lose. Because a typical DART page loads only 10-20 kilobytes of HTML, it renders quickly, taking advantage of all the browser's rendering optimizations.","title":"MVC Pattern"},{"location":"developers/building/","text":"Building DART Once you've cloned the DART source code from GitHub , there are two ways to build the application. cd into the DART project directory and run the command ./node_modules/.bin/electron-builder . This will run a command-line build for your platform. cd into the DART project directory and run the command npm run electron-toolkit . This will present a GUI that makes it easy to customize your build and to build DART for other platforms.","title":"Building"},{"location":"developers/building/#building-dart","text":"Once you've cloned the DART source code from GitHub , there are two ways to build the application. cd into the DART project directory and run the command ./node_modules/.bin/electron-builder . This will run a command-line build for your platform. cd into the DART project directory and run the command npm run electron-toolkit . This will present a GUI that makes it easy to customize your build and to build DART for other platforms.","title":"Building DART"},{"location":"developers/data_storage/","text":"Data Storage DART stores all of its settings data in plain text JSON files. You find these files in the DART data directory. Choose Help About from the DART menu to find the data directory on your system. You'll see a dialog like the following. DART uses the simple conf module to read, write, and search data, and write-file-atomic to prevent write conflicts. If you want to dig further into DART's data persistence, see the documentation for JsonStore and PersistentObject . You can examine DART's data stores by opening the JSON files, or in the console by following these steps: Open DART by running npm start from the DART project directory. Right click anywhere on the page and choose Inspect Element from the context menu. Swich to the Console view in the developer tools window. Type DART.Core.Context.dataStores in the console.","title":"Data Storage"},{"location":"developers/data_storage/#data-storage","text":"DART stores all of its settings data in plain text JSON files. You find these files in the DART data directory. Choose Help About from the DART menu to find the data directory on your system. You'll see a dialog like the following. DART uses the simple conf module to read, write, and search data, and write-file-atomic to prevent write conflicts. If you want to dig further into DART's data persistence, see the documentation for JsonStore and PersistentObject . You can examine DART's data stores by opening the JSON files, or in the console by following these steps: Open DART by running npm start from the DART project directory. Right click anywhere on the page and choose Inspect Element from the context menu. Swich to the Console view in the developer tools window. Type DART.Core.Context.dataStores in the console.","title":"Data Storage"},{"location":"developers/documenting/","text":"Documenting DART If you contribute code to DART, please document it for the sanity of the people who will maintain it. DART uses JSDoc to generate the DART API documentation . Look at the source code for examples of how we use JSDoc. In addition to documenting your API methods, you should comment sections of your code in which the logic or behavior is not obvious. Always code as if the guy who ends up maintaining your code will be a violent psychopath who knows where you live. -- John F. Woods","title":"Documenting"},{"location":"developers/documenting/#documenting-dart","text":"If you contribute code to DART, please document it for the sanity of the people who will maintain it. DART uses JSDoc to generate the DART API documentation . Look at the source code for examples of how we use JSDoc. In addition to documenting your API methods, you should comment sections of your code in which the logic or behavior is not obvious. Always code as if the guy who ends up maintaining your code will be a violent psychopath who knows where you live. -- John F. Woods","title":"Documenting DART"},{"location":"developers/job_flow/","text":"Job Flow All DART jobs are run as individual processes. When you run a job from the DART UI, the application forks a child process and runs the job in that process. The code that forks the child is in the run method of the JobRunController , which is documented here . Forking child processes has a number of advantages over running jobs in the same process as the UI. You can run multiple jobs simultaneously. You can continue to use the UI while jobs run. A crashed job will not crash the UI. The downside of running jobs in child processes is that if you close the DART application, you kill all of the running jobs. This is why DART always displays a badge in the upper right corner when jobs are running. All DART jobs, whether run from the UI or from the command line, are launched from the run() method of main.js , which does the following: Calls the JobLoader to load the job. Info The JobLoader figures out whether you're passing in a Job object or some other type of object from which it can construct a job. You'll typically pass in JSON representing a lightweight JobParams object and the JobLoader will construct the job from that. The JobParams object simply names a set of files, a Workflow to pass them through, and a set of metadata tags to add to the package. The user documentaiton for JobParams will be helpful to developers. Passes the Job object to the JobRunner and then calls the JobRunner's run method. Returns the exit code so that the script or application that launched the job can know whether it succeeded. An exit code of zero indicates success. Any other code indicates failure. These codes are spelled out in core/constants.js as follows: /** * This exit code indicates a process completed successfully, * with no errors. * * @type {number} */ EXIT_SUCCESS : 0 , /** * This exit code indicates a process ran to completion, but one * or more errors occurred along the way. * * @type {number} */ EXIT_COMPLETED_WITH_ERRORS : 1 , /** * This exit code indicates a process did not complete * due to invalid parameters. * * @type {number} */ EXIT_INVALID_PARAMS : 2 , /** * This exit code indicates that the process did not complete * due to an unexpected runtime error. * * @type {number} */ EXIT_RUNTIME_ERROR : 3 , The JobRunner, Step by Step The JobRunner does the following: If the Job includes a PackageOperation , the JobRunner packages the files specified in the operation. The PackageOperation describes how DART should create a bag, or a tar file, or a zip file, or some other package. If a user wants to upload files without packaging, there will be no PackageOperation. If the PackageOperation produced a BagIt bag (tarred or not), DART validates the bag. The JobRunner will create a ValidationOperation to describe what needs to be validated and how. If the job includes any UploadOperations , DART will execute them one at a time, in sequence. The JobRunner sets and returns the appropriate exit code. (Note that the most common cause of the EXIT_COMPLETED_WITH_ERRORS code is a job whose packaging and validation succeeded, along with some but not all of the upload operations.) The JobRunner logs its work, and you can watch the operations unfold in the logs . Each of the objects PackageOperation , ValidationOperation , and UploadOperation include an OperationResult object. After a job is complete, each of the operations and their results are stored with the job record in the DART's jobs database, which is a plain text JSON file. You can open the file directly to examine the full state of the object. See Data Storage for more information. All of the code for running jobs lives in the workers folder of the DART source. The four key files have the following tasks: workers/job_runner.js orchestrates the work of bagging, validating, and uploading. Links: source code , documentation , tests . workers/bag_creator.js creates bags for the PackageOperation step of the job. Links: source code , documentation , tests . workers/bag_validator.js validates that a bag is complete and conforms to a specified BagIt profile. Links: source , documentation , tests . workers/uploader.js uploads files to a remote upload target. Links: source , documentation , tests .","title":"Job Flow"},{"location":"developers/job_flow/#job-flow","text":"All DART jobs are run as individual processes. When you run a job from the DART UI, the application forks a child process and runs the job in that process. The code that forks the child is in the run method of the JobRunController , which is documented here . Forking child processes has a number of advantages over running jobs in the same process as the UI. You can run multiple jobs simultaneously. You can continue to use the UI while jobs run. A crashed job will not crash the UI. The downside of running jobs in child processes is that if you close the DART application, you kill all of the running jobs. This is why DART always displays a badge in the upper right corner when jobs are running. All DART jobs, whether run from the UI or from the command line, are launched from the run() method of main.js , which does the following: Calls the JobLoader to load the job. Info The JobLoader figures out whether you're passing in a Job object or some other type of object from which it can construct a job. You'll typically pass in JSON representing a lightweight JobParams object and the JobLoader will construct the job from that. The JobParams object simply names a set of files, a Workflow to pass them through, and a set of metadata tags to add to the package. The user documentaiton for JobParams will be helpful to developers. Passes the Job object to the JobRunner and then calls the JobRunner's run method. Returns the exit code so that the script or application that launched the job can know whether it succeeded. An exit code of zero indicates success. Any other code indicates failure. These codes are spelled out in core/constants.js as follows: /** * This exit code indicates a process completed successfully, * with no errors. * * @type {number} */ EXIT_SUCCESS : 0 , /** * This exit code indicates a process ran to completion, but one * or more errors occurred along the way. * * @type {number} */ EXIT_COMPLETED_WITH_ERRORS : 1 , /** * This exit code indicates a process did not complete * due to invalid parameters. * * @type {number} */ EXIT_INVALID_PARAMS : 2 , /** * This exit code indicates that the process did not complete * due to an unexpected runtime error. * * @type {number} */ EXIT_RUNTIME_ERROR : 3 ,","title":"Job Flow"},{"location":"developers/job_flow/#the-jobrunner-step-by-step","text":"The JobRunner does the following: If the Job includes a PackageOperation , the JobRunner packages the files specified in the operation. The PackageOperation describes how DART should create a bag, or a tar file, or a zip file, or some other package. If a user wants to upload files without packaging, there will be no PackageOperation. If the PackageOperation produced a BagIt bag (tarred or not), DART validates the bag. The JobRunner will create a ValidationOperation to describe what needs to be validated and how. If the job includes any UploadOperations , DART will execute them one at a time, in sequence. The JobRunner sets and returns the appropriate exit code. (Note that the most common cause of the EXIT_COMPLETED_WITH_ERRORS code is a job whose packaging and validation succeeded, along with some but not all of the upload operations.) The JobRunner logs its work, and you can watch the operations unfold in the logs . Each of the objects PackageOperation , ValidationOperation , and UploadOperation include an OperationResult object. After a job is complete, each of the operations and their results are stored with the job record in the DART's jobs database, which is a plain text JSON file. You can open the file directly to examine the full state of the object. See Data Storage for more information. All of the code for running jobs lives in the workers folder of the DART source. The four key files have the following tasks: workers/job_runner.js orchestrates the work of bagging, validating, and uploading. Links: source code , documentation , tests . workers/bag_creator.js creates bags for the PackageOperation step of the job. Links: source code , documentation , tests . workers/bag_validator.js validates that a bag is complete and conforms to a specified BagIt profile. Links: source , documentation , tests . workers/uploader.js uploads files to a remote upload target. Links: source , documentation , tests .","title":"The JobRunner, Step by Step"},{"location":"developers/logging/","text":"Logging DART uses the Winston library for logging. You can find the location of your DART logs by choosing Help About from the main menu. You should see a dialog like this: As you develop, you can tail the logs to see what's happening in real time. Just substitute the proper log location in the command below. tail - f / Users / apd4n / Library / Logs / DART / dart . log Also note that you can tail the logs directly from DART by choose Help Logs from the menu. While this approach is handy, there are two caveats. First, if the log file is large, the log window may take a long time to load. Second, DART rotates its logs when they reach a size of 5 MB. If that rollover happens while you're tailing the log in the DART log window, you won't see any entries logged after the rollover. DART logs to a different file when it runs unit tests, usually to a directory called .dart-test/log/dart.log . For more information on logging, see the code in util/logger.js and the config settings in core/config.js .","title":"Logging"},{"location":"developers/logging/#logging","text":"DART uses the Winston library for logging. You can find the location of your DART logs by choosing Help About from the main menu. You should see a dialog like this: As you develop, you can tail the logs to see what's happening in real time. Just substitute the proper log location in the command below. tail - f / Users / apd4n / Library / Logs / DART / dart . log Also note that you can tail the logs directly from DART by choose Help Logs from the menu. While this approach is handy, there are two caveats. First, if the log file is large, the log window may take a long time to load. Second, DART rotates its logs when they reach a size of 5 MB. If that rollover happens while you're tailing the log in the DART log window, you won't see any entries logged after the rollover. DART logs to a different file when it runs unit tests, usually to a directory called .dart-test/log/dart.log . For more information on logging, see the code in util/logger.js and the config settings in core/config.js .","title":"Logging"},{"location":"developers/testing/","text":"Testing DART DART uses Jest for testing. You can run DART's test suite with this command npm test -- --runInBand Note that the --runInBand option is required as a number of tests save fixture data to DART's disk-based data store. Because that data is globally accessible, tests must run in sequence to avoid deleting and overwriting data that other tests expect to be in a known state. Test Code You Add If you're adding code to DART, please write tests to ensure your code behaves as expected.","title":"Testing"},{"location":"developers/testing/#testing-dart","text":"DART uses Jest for testing. You can run DART's test suite with this command npm test -- --runInBand Note that the --runInBand option is required as a number of tests save fixture data to DART's disk-based data store. Because that data is globally accessible, tests must run in sequence to avoid deleting and overwriting data that other tests expect to be in a known state.","title":"Testing DART"},{"location":"developers/testing/#test-code-you-add","text":"If you're adding code to DART, please write tests to ensure your code behaves as expected.","title":"Test Code You Add"},{"location":"developers/plugins/","text":"Plugins Plugins allow DART to read and write data formats (such as tar, zip, etc.), to upload and download files using various protocols (such as s3, ftp, etc.), to communicate with the REST APIs of remote repositories (such as APTrust) and to help users through the complexities of initial setup and configuration (such as the APTrust and DPN setup modules). DART plugins are written in plain JavaScript and HTML. Developers may contribute new plugins without having to learn DART's internals. A plugin simply has to conform to a simple API, which it typically limited to a small number of well-defined methods. The documentation in this section gives a high-level overview plugin structure and behavior as a starting point for developing your own plugins. You'll find more detail information in DART's API documentation and source code, as well as in the unit tests that accompany existing plugins. Along with an overview of each plugin type, this documentation provides relevant links to source and test code for further study. The Base Plugin DART's base Plugin object is simply an EventEmitter with a static method that returns a description. The description includes the following fields: id - A UUID string that uniquely identifies the plugin. When writing a plugin, you should generate this once. It lives from then on as a hard-coded identifier. name - The name of the plugin. This will appear in parts of the DART UI that use the plugin. description - A description of what the plugin does. version - The plugin version, which is a string. E.g. '1.0.14'. readsFormats - A list of strings, this applies only to plugins that can read data from formats such as zip, tar, rar, parchive, etc. The values in this field should be the file extensions of the types of files the plugin can read. For example, ['.tar.', '.gz', '.gzip', '.tar.gz']. This should be empty for plugins that are not intended to read file formats. Use all lower case letters. writesFormats - A list of strings indicating the file formats the plugin can write. E.g. ['.tar.', '.gz', '.gzip', '.tar.gz']. This should be empty for plugins that are not intended to write file formats. Use all lower case letters. implementsProtocols - The network protocols that this plugin implements. For example, an FTP plugin may implement ['ftp', 'sftp', 'ftps']. This applies only to plugins of type NetworkClient. If your plugin is not a NetworkClient, this should be an empty list. Use all lower case letters. setsUp - This describes what general configuration your plugin provides. For example, the 'aptrust' setup plugin helps the user configure some basic APTrust settings, such as the URL of the APTrust repository, the user's API keys, etc. This applies only to plugins of type Setup. If your plugin is not a Setup plugin, this should be empty. Use all lower case letters. talksToRepository - This describes what type of repository your plugin talks to. For example, 'fedora', 'aptrust', etc. This applies only to plugins of type Repository. If your plugin is not a Repository plugin, this should be empty. Use all lower case letters. The PluginManager uses these descriptions to tell the application what plugins are available and what capabilities they have. Plugins are EventEmitters. They can work synchronously or asynchronously, but they must emit a standard set of events to communicate with the UI (or the JobRunner , when DART runs in command-line mode). Plugin Types Format Readers read file formats, such as tar, zip, and anything else a developer might want. Format Writers write file formats. Network Clients provide methods for uploading and download via different network protocols. Repo Clients provide communication between DART and the REST APIs of remote repositories. Setup Modules automate pars of the setup and configuration process, and provide one-at-a-time walkthrough questions to help users configure their DART environment. The PluginManager provides methods for discovering and loading installed plugins.","title":"Plugins"},{"location":"developers/plugins/#plugins","text":"Plugins allow DART to read and write data formats (such as tar, zip, etc.), to upload and download files using various protocols (such as s3, ftp, etc.), to communicate with the REST APIs of remote repositories (such as APTrust) and to help users through the complexities of initial setup and configuration (such as the APTrust and DPN setup modules). DART plugins are written in plain JavaScript and HTML. Developers may contribute new plugins without having to learn DART's internals. A plugin simply has to conform to a simple API, which it typically limited to a small number of well-defined methods. The documentation in this section gives a high-level overview plugin structure and behavior as a starting point for developing your own plugins. You'll find more detail information in DART's API documentation and source code, as well as in the unit tests that accompany existing plugins. Along with an overview of each plugin type, this documentation provides relevant links to source and test code for further study.","title":"Plugins"},{"location":"developers/plugins/#the-base-plugin","text":"DART's base Plugin object is simply an EventEmitter with a static method that returns a description. The description includes the following fields: id - A UUID string that uniquely identifies the plugin. When writing a plugin, you should generate this once. It lives from then on as a hard-coded identifier. name - The name of the plugin. This will appear in parts of the DART UI that use the plugin. description - A description of what the plugin does. version - The plugin version, which is a string. E.g. '1.0.14'. readsFormats - A list of strings, this applies only to plugins that can read data from formats such as zip, tar, rar, parchive, etc. The values in this field should be the file extensions of the types of files the plugin can read. For example, ['.tar.', '.gz', '.gzip', '.tar.gz']. This should be empty for plugins that are not intended to read file formats. Use all lower case letters. writesFormats - A list of strings indicating the file formats the plugin can write. E.g. ['.tar.', '.gz', '.gzip', '.tar.gz']. This should be empty for plugins that are not intended to write file formats. Use all lower case letters. implementsProtocols - The network protocols that this plugin implements. For example, an FTP plugin may implement ['ftp', 'sftp', 'ftps']. This applies only to plugins of type NetworkClient. If your plugin is not a NetworkClient, this should be an empty list. Use all lower case letters. setsUp - This describes what general configuration your plugin provides. For example, the 'aptrust' setup plugin helps the user configure some basic APTrust settings, such as the URL of the APTrust repository, the user's API keys, etc. This applies only to plugins of type Setup. If your plugin is not a Setup plugin, this should be empty. Use all lower case letters. talksToRepository - This describes what type of repository your plugin talks to. For example, 'fedora', 'aptrust', etc. This applies only to plugins of type Repository. If your plugin is not a Repository plugin, this should be empty. Use all lower case letters. The PluginManager uses these descriptions to tell the application what plugins are available and what capabilities they have. Plugins are EventEmitters. They can work synchronously or asynchronously, but they must emit a standard set of events to communicate with the UI (or the JobRunner , when DART runs in command-line mode).","title":"The Base Plugin"},{"location":"developers/plugins/#plugin-types","text":"Format Readers read file formats, such as tar, zip, and anything else a developer might want. Format Writers write file formats. Network Clients provide methods for uploading and download via different network protocols. Repo Clients provide communication between DART and the REST APIs of remote repositories. Setup Modules automate pars of the setup and configuration process, and provide one-at-a-time walkthrough questions to help users configure their DART environment. The PluginManager provides methods for discovering and loading installed plugins.","title":"Plugin Types"},{"location":"developers/plugins/format_readers/","text":"Format Readers Format readers read file formats like tar, zip, OCFL, etc. Format readers provide methods for listing the contents of a directory or serialized file, and for reading individual files from the directory/file. The initial release of DART 2.0 includes two format readers: a FileSystemReader and a TarReader . Developers can use these two examples as references for how to write a format reader. API and Events Format readers must extend the DART base Plugin and providing a description() method that returns meaningful PluginDescription information. Format readers must implement the following methods: A constructor that takes a single parameter, which is the path to the file that the reader will read. (If the reader reads from a directory, such as an OCFL object, the path should point to a directory.) A static definition method that takes no parameters and returns a description of the plugin (as described in The Base Plugin ). A read method that takes no parameters and emits events entry , error , and end (described below). A list method that takes no parameters and emits events entry , error , and end (described below). Property fileCount , a number that starts at zero and is incremented by one each time read or list emits an entry event for a file. Property dirCount , a number that starts at zero and is incremented by one each time read or list emits an entry event for a directory. Property byteCount , a number that starts at zero and is incremented by the number of bytes in a file each time read or list emits an entry event for a file. The error event passes a JavaScript error object to registered listeners and causes DART to stop reading. The end event passes nothing to registered listeners and tells DART that the reader has finished with all entries. The entry event passes an object containing the relative path of the current file entry, a lightweight FileStat object, and in the case a of the read method, an open Readable stream so DART can read the contents of the file. Note DART uses its own simplified FileStat object instead of Node's built-in Stats object because format readers will often have to read from serialized formats that don't include all of the information you'd find in a Stats object. For example, tar and zip headers may exclude information about inode, blocksize, etc. The FileStat object simply captures the essentials that are common across most formats. Tip In cases where a FormatReader's read method cannot return a readable stream, it can return a DummyReader . This is necessary in cases where the reader encounters a directory entry that cannot be read like a regular file. DART will still try to read from the readable stream in the entry event, and a DummyReader will allow DART to read without error. For an example of how to do this, look for DummyReader in the read method of the FileSystemReader source code. Format Reader Examples The best way to understand how to write a FormatReader plugin is to review the API documentation, source code, and tests for the following: FileSystemReader , which provides a working example. The FileSystemReader tests , which show how the reader is expected to behave. TarReader . The TarReader tests , which show how the TarReader is expected to behave. The FileStat documentation, which shows the structure of the FileStat object.","title":"Format Readers"},{"location":"developers/plugins/format_readers/#format-readers","text":"Format readers read file formats like tar, zip, OCFL, etc. Format readers provide methods for listing the contents of a directory or serialized file, and for reading individual files from the directory/file. The initial release of DART 2.0 includes two format readers: a FileSystemReader and a TarReader . Developers can use these two examples as references for how to write a format reader.","title":"Format Readers"},{"location":"developers/plugins/format_readers/#api-and-events","text":"Format readers must extend the DART base Plugin and providing a description() method that returns meaningful PluginDescription information. Format readers must implement the following methods: A constructor that takes a single parameter, which is the path to the file that the reader will read. (If the reader reads from a directory, such as an OCFL object, the path should point to a directory.) A static definition method that takes no parameters and returns a description of the plugin (as described in The Base Plugin ). A read method that takes no parameters and emits events entry , error , and end (described below). A list method that takes no parameters and emits events entry , error , and end (described below). Property fileCount , a number that starts at zero and is incremented by one each time read or list emits an entry event for a file. Property dirCount , a number that starts at zero and is incremented by one each time read or list emits an entry event for a directory. Property byteCount , a number that starts at zero and is incremented by the number of bytes in a file each time read or list emits an entry event for a file. The error event passes a JavaScript error object to registered listeners and causes DART to stop reading. The end event passes nothing to registered listeners and tells DART that the reader has finished with all entries. The entry event passes an object containing the relative path of the current file entry, a lightweight FileStat object, and in the case a of the read method, an open Readable stream so DART can read the contents of the file. Note DART uses its own simplified FileStat object instead of Node's built-in Stats object because format readers will often have to read from serialized formats that don't include all of the information you'd find in a Stats object. For example, tar and zip headers may exclude information about inode, blocksize, etc. The FileStat object simply captures the essentials that are common across most formats. Tip In cases where a FormatReader's read method cannot return a readable stream, it can return a DummyReader . This is necessary in cases where the reader encounters a directory entry that cannot be read like a regular file. DART will still try to read from the readable stream in the entry event, and a DummyReader will allow DART to read without error. For an example of how to do this, look for DummyReader in the read method of the FileSystemReader source code.","title":"API and Events"},{"location":"developers/plugins/format_readers/#format-reader-examples","text":"The best way to understand how to write a FormatReader plugin is to review the API documentation, source code, and tests for the following: FileSystemReader , which provides a working example. The FileSystemReader tests , which show how the reader is expected to behave. TarReader . The TarReader tests , which show how the TarReader is expected to behave. The FileStat documentation, which shows the structure of the FileStat object.","title":"Format Reader Examples"},{"location":"developers/plugins/format_writers/","text":"Format Writers Format writers write file formats like tar, zip, OCFL, etc. Format writers provide methods for writing contents into a directory or serialized file. The initial release of DART 2.0 includes two format writers: a FileSystemWriter and a TarWriter . Developers can use these two examples as references for how to write a format writer. Format writers may be synchronous or asynchronous under the hood. Certain types of writers, such as the built-in TarWriter MUST be synchronous internally because the tar format requires files to be written one at a time, in order. To assist with this, the BaseWriter implements a queue that executes requests sequentially, in the order they were received, with each write request beginning only after the last write has completed. API and Events Format writers should extend the DART BaseWriter and provide a description() method that returns meaningful PluginDescription information. Format writers must implement the following methods: A constructor that takes a single parameter, which is the path to the file or directory that the reader will write. A static definition method that takes no parameters and returns a description of the plugin (as described in The Base Plugin ). An add method that takes two parameters: a BagItFile and an options list of cryptographic hash algorithm names (such as 'md5', 'sha256', etc.). This method must emit a fileAdded event each time it writes a file into the target directory (or tar archive, zip archive, etc). The fileAdded event ... TODO: WRITE ME The error event ... TODO: WRITE ME The finish event ... TODO: WRITE ME","title":"Format Writers"},{"location":"developers/plugins/format_writers/#format-writers","text":"Format writers write file formats like tar, zip, OCFL, etc. Format writers provide methods for writing contents into a directory or serialized file. The initial release of DART 2.0 includes two format writers: a FileSystemWriter and a TarWriter . Developers can use these two examples as references for how to write a format writer. Format writers may be synchronous or asynchronous under the hood. Certain types of writers, such as the built-in TarWriter MUST be synchronous internally because the tar format requires files to be written one at a time, in order. To assist with this, the BaseWriter implements a queue that executes requests sequentially, in the order they were received, with each write request beginning only after the last write has completed.","title":"Format Writers"},{"location":"developers/plugins/format_writers/#api-and-events","text":"Format writers should extend the DART BaseWriter and provide a description() method that returns meaningful PluginDescription information. Format writers must implement the following methods: A constructor that takes a single parameter, which is the path to the file or directory that the reader will write. A static definition method that takes no parameters and returns a description of the plugin (as described in The Base Plugin ). An add method that takes two parameters: a BagItFile and an options list of cryptographic hash algorithm names (such as 'md5', 'sha256', etc.). This method must emit a fileAdded event each time it writes a file into the target directory (or tar archive, zip archive, etc). The fileAdded event ... TODO: WRITE ME The error event ... TODO: WRITE ME The finish event ... TODO: WRITE ME","title":"API and Events"},{"location":"developers/plugins/manager/","text":"Plugin Manager DART's PluginManager provides methods that allow the appication to discover and load plugins. DART uses the findById method to load individual plugins, and the following methods to discover available plugins: getModuleCollection() - This returns information about plugins of a specified type, such as Repo Clients or Network Clients . The list of plugins returned by this method appears on some configuration screens. For example, when a user sets up a new StorageService , a list of available network clients appears so the user can choose which client/protocol should be used to communicate with that service. DART's JobRunner uses the methods canRead(), canWrite(), implementsProtocol(), talksTo(), and setsUp() to figure out which plugins to use to complete each operation within a job. See also: PluginManager API , PluginManager source","title":"Plugin Manager"},{"location":"developers/plugins/manager/#plugin-manager","text":"DART's PluginManager provides methods that allow the appication to discover and load plugins. DART uses the findById method to load individual plugins, and the following methods to discover available plugins: getModuleCollection() - This returns information about plugins of a specified type, such as Repo Clients or Network Clients . The list of plugins returned by this method appears on some configuration screens. For example, when a user sets up a new StorageService , a list of available network clients appears so the user can choose which client/protocol should be used to communicate with that service. DART's JobRunner uses the methods canRead(), canWrite(), implementsProtocol(), talksTo(), and setsUp() to figure out which plugins to use to complete each operation within a job. See also: PluginManager API , PluginManager source","title":"Plugin Manager"},{"location":"developers/plugins/network_clients/","text":"Network Clients What they do. How they enable new types of storage services. How they show up in the providers list. How to write one.","title":"Network Clients"},{"location":"developers/plugins/network_clients/#network-clients","text":"What they do. How they enable new types of storage services. How they show up in the providers list. How to write one.","title":"Network Clients"},{"location":"developers/plugins/repo_clients/","text":"Repository Clients What they do. Requirements: REST API. Inputs and outputs.","title":"Repository Clients"},{"location":"developers/plugins/repo_clients/#repository-clients","text":"What they do. Requirements: REST API. Inputs and outputs.","title":"Repository Clients"},{"location":"developers/plugins/setup_modules/","text":"Setup Modules Describe what they do and why they're useful. Describe how to build and test them.","title":"Setup Modules"},{"location":"developers/plugins/setup_modules/#setup-modules","text":"Describe what they do and why they're useful. Describe how to build and test them.","title":"Setup Modules"},{"location":"users/command_line/","text":"Command Line Reference DART provides several ways of running jobs from the command line. The most convenient method, and the easiest to script, is to define a workflow and then create a JobParams object that describes which files to pass through the workflow and what custom metadata attributes to assign. Note that in all of these examples, the dart command is followed by two dashes, and then the command-line parameters. Parameters to the left of the double dash will be consumed by the Node.js runtime, while those to the right will be passed to DART. From a JobParams JSON file dart -- --job path/to/job_params.json From JobParams JSON passed through STDIN echo \"{ ... json ... } | dart -- --stdin\" From a Job JSON file dart -- --job path/to/job.json Note: DART does not yet export jobs to JSON. That feature is in the works. From Job JSON passed through STDIN echo { ... json ... } | dart -- --stdin Note Job JSON can be relatively large, since it may include a BagIt profile. Using JobParams is generally easier than using Jobs. By Job UUID dart -- --job 00000000-0000-0000-0000-000000000000 Note The ability to extract Job UUIDs from DART is coming soon. As of this writing (July 22, 2019), some elements of the CLI are subject to change and further development. Resource Usage and Known Issues DART uses Node.js, which is a relatively fast, efficient JavaScript runtime. Node, however, can use large amounts of memory, often 10-30 times what a similar application written in Go or C++ may use. You can expect each DART command-line process to use at least 50 MB of RAM on startup, and sometimes over 150 MB at runtime if it when creating large packages. Potentially High Memory Usage During S3 Uploads DART consumes the most memory when uploading large files to an S3-compliant endpoint. S3 clients need to load chunks of data into memory before streaming them across the network. When uploading a file of 100 MB, each chunk may be only 5-50 MB in size, increasing DART's memory usage by that amound until the chunk has been copied to the remote server. S3 allows uploads of up to 5 TB, with a maximum of 10,000 chunks. This means that when uploading a 5 TB file, DART's underlying S3 client will load chunks of about 535 MB each into memory. That's a considerable amount of memory, particularly on a computer that likely has a number of other open appilcations. For this reason, it's best to avoid running multiple simultaneous multi-terabyte jobs. Disk Usage When Creating Large Packages When you're packaging very large files, keep in mind that you may run out of disk space. For example, DART needs about 5 TB of disk space to create a 5 TB bag. DART is fairly efficient about this, writing contents directly into a tar archive when possible to avoid multiple copies, and calculating all checksums in a single pass during the writes. However, if you're creating a 5 TB bag and you don't have 5 TB of disk space, the job is going to fail. Note that you can change the location of your bagging directory by choosing Settings App Settings from the menu and then clicking Bagging Directory . You can also change your bagging directory for a single job by setting the Output Path for that job. If you need extra disk space for a particular job, consider using a network share or an external USB drive as your bagging directory. Checking the Logs for Failed Jobs DART logs all of its work. If a job fails, check the logs for details. Sharing Jobs Note that because details of jobs, workflows, and storage services are stored on your local DART computer, workflows and JobParams defined on one machine will not run on another machine that does not have matching settings.","title":"Command Line Reference"},{"location":"users/command_line/#command-line-reference","text":"DART provides several ways of running jobs from the command line. The most convenient method, and the easiest to script, is to define a workflow and then create a JobParams object that describes which files to pass through the workflow and what custom metadata attributes to assign. Note that in all of these examples, the dart command is followed by two dashes, and then the command-line parameters. Parameters to the left of the double dash will be consumed by the Node.js runtime, while those to the right will be passed to DART. From a JobParams JSON file dart -- --job path/to/job_params.json From JobParams JSON passed through STDIN echo \"{ ... json ... } | dart -- --stdin\" From a Job JSON file dart -- --job path/to/job.json Note: DART does not yet export jobs to JSON. That feature is in the works. From Job JSON passed through STDIN echo { ... json ... } | dart -- --stdin Note Job JSON can be relatively large, since it may include a BagIt profile. Using JobParams is generally easier than using Jobs. By Job UUID dart -- --job 00000000-0000-0000-0000-000000000000 Note The ability to extract Job UUIDs from DART is coming soon. As of this writing (July 22, 2019), some elements of the CLI are subject to change and further development.","title":"Command Line Reference"},{"location":"users/command_line/#resource-usage-and-known-issues","text":"DART uses Node.js, which is a relatively fast, efficient JavaScript runtime. Node, however, can use large amounts of memory, often 10-30 times what a similar application written in Go or C++ may use. You can expect each DART command-line process to use at least 50 MB of RAM on startup, and sometimes over 150 MB at runtime if it when creating large packages.","title":"Resource Usage and Known Issues"},{"location":"users/command_line/#potentially-high-memory-usage-during-s3-uploads","text":"DART consumes the most memory when uploading large files to an S3-compliant endpoint. S3 clients need to load chunks of data into memory before streaming them across the network. When uploading a file of 100 MB, each chunk may be only 5-50 MB in size, increasing DART's memory usage by that amound until the chunk has been copied to the remote server. S3 allows uploads of up to 5 TB, with a maximum of 10,000 chunks. This means that when uploading a 5 TB file, DART's underlying S3 client will load chunks of about 535 MB each into memory. That's a considerable amount of memory, particularly on a computer that likely has a number of other open appilcations. For this reason, it's best to avoid running multiple simultaneous multi-terabyte jobs.","title":"Potentially High Memory Usage During S3 Uploads"},{"location":"users/command_line/#disk-usage-when-creating-large-packages","text":"When you're packaging very large files, keep in mind that you may run out of disk space. For example, DART needs about 5 TB of disk space to create a 5 TB bag. DART is fairly efficient about this, writing contents directly into a tar archive when possible to avoid multiple copies, and calculating all checksums in a single pass during the writes. However, if you're creating a 5 TB bag and you don't have 5 TB of disk space, the job is going to fail. Note that you can change the location of your bagging directory by choosing Settings App Settings from the menu and then clicking Bagging Directory . You can also change your bagging directory for a single job by setting the Output Path for that job. If you need extra disk space for a particular job, consider using a network share or an external USB drive as your bagging directory.","title":"Disk Usage When Creating Large Packages"},{"location":"users/command_line/#checking-the-logs-for-failed-jobs","text":"DART logs all of its work. If a job fails, check the logs for details.","title":"Checking the Logs for Failed Jobs"},{"location":"users/command_line/#sharing-jobs","text":"Note that because details of jobs, workflows, and storage services are stored on your local DART computer, workflows and JobParams defined on one machine will not run on another machine that does not have matching settings.","title":"Sharing Jobs"},{"location":"users/dashboard/","text":"Dashboard The dashboard shows running jobs, recently completed jobs, and selected items from remote repositories. Running Jobs The Running Jobs panel shows jobs DART is currently running on your computer. If more than one job is currently running, you can scroll inside the panel to see the progress of each. Also note the blue badge in the upper right corner of the window showing there are two running jobs. The blue badge appears on all DART views as long as jobs are running. Note that DART runs each job in a separate process. Actions you take in DART do not affect the running jobs. Warning When you shut down the DART application, all DART jobs stop, even if they are not yet complete. Don't close the DART window while jobs are running, unless you intend to stop all of the jobs. Progress Bars for Running Jobs The progress bars for running jobs show how much progress DART has made in each of the job's steps, which may include packaging, validation, and/or uploading. Info While the progress bars for packaging and validation are very accurate, the progress bar for uploads runs slightly ahead of the actual upload progress. DART knows how many bytes of an upload it has prepared to send, but not how many have been received by the remote host. It's common for the upload progress bar to appear to stall at about 98% while the last chunk of data goes across the wire. For smaller uploads, the stall may last only a second or two. For very large uploads, the final chunk may be hundreds of megabytes and may take several minutes to complete. Recent Jobs The Recent Jobs panel lists recently completed jobs. The Outcome column shows the job's last completed step, while the Date column shows when that step was completed. You can get more detailed information by clicking Jobs List from the top menu. See also: Jobs Repositories The Repositories panels show items from remote repositories that DART knows how to connect to. In the screenshot above, this panel shows items recently ingested into APTrust's demo repository: The panel below shows a list of pending or recently completed tasks from APTrust demo system. Some repository panels, such as those from APTrust, show additional information when you mouse over an item. The panels show errors if they cannot communicate with the remote repository. If you run into errors like this, chances are your Remote Repository is incorrectly configured. Info Remote repository panels require both a correctly configured Remote Repository setting and a plugin that knows how to communicate with the remote repository. Plugins are typically written by developers associated with the repository, and are packaged with the DART installation. See also: Remote Repository","title":"Dashboard"},{"location":"users/dashboard/#dashboard","text":"The dashboard shows running jobs, recently completed jobs, and selected items from remote repositories.","title":"Dashboard"},{"location":"users/dashboard/#running-jobs","text":"The Running Jobs panel shows jobs DART is currently running on your computer. If more than one job is currently running, you can scroll inside the panel to see the progress of each. Also note the blue badge in the upper right corner of the window showing there are two running jobs. The blue badge appears on all DART views as long as jobs are running. Note that DART runs each job in a separate process. Actions you take in DART do not affect the running jobs. Warning When you shut down the DART application, all DART jobs stop, even if they are not yet complete. Don't close the DART window while jobs are running, unless you intend to stop all of the jobs.","title":"Running Jobs"},{"location":"users/dashboard/#progress-bars-for-running-jobs","text":"The progress bars for running jobs show how much progress DART has made in each of the job's steps, which may include packaging, validation, and/or uploading. Info While the progress bars for packaging and validation are very accurate, the progress bar for uploads runs slightly ahead of the actual upload progress. DART knows how many bytes of an upload it has prepared to send, but not how many have been received by the remote host. It's common for the upload progress bar to appear to stall at about 98% while the last chunk of data goes across the wire. For smaller uploads, the stall may last only a second or two. For very large uploads, the final chunk may be hundreds of megabytes and may take several minutes to complete.","title":"Progress Bars for Running Jobs"},{"location":"users/dashboard/#recent-jobs","text":"The Recent Jobs panel lists recently completed jobs. The Outcome column shows the job's last completed step, while the Date column shows when that step was completed. You can get more detailed information by clicking Jobs List from the top menu. See also: Jobs","title":"Recent Jobs"},{"location":"users/dashboard/#repositories","text":"The Repositories panels show items from remote repositories that DART knows how to connect to. In the screenshot above, this panel shows items recently ingested into APTrust's demo repository: The panel below shows a list of pending or recently completed tasks from APTrust demo system. Some repository panels, such as those from APTrust, show additional information when you mouse over an item. The panels show errors if they cannot communicate with the remote repository. If you run into errors like this, chances are your Remote Repository is incorrectly configured. Info Remote repository panels require both a correctly configured Remote Repository setting and a plugin that knows how to communicate with the remote repository. Plugins are typically written by developers associated with the repository, and are packaged with the DART installation. See also: Remote Repository","title":"Repositories"},{"location":"users/getting_started/","text":"Getting Started DART is the Digital Archivist's Resource Tool. Its primary purpose is to package digital materials and send them off to long-term preservation storage. DART's initial release focuses on packaging materials in BagIt format and uploading them to S3 buckets for ingest in APTrust. DART can be extended through plugins to produce other packaging formats and to communicated via additional network protocols. DART runs in both graphical and command-line modes on Windows, Mac, and Linux. Installation Download the DART installer for your system. Mac : https://s3.amazonaws.com/aptrust.public.download/DART/DART-2.0.0.dmg Windows : https://s3.amazonaws.com/aptrust.public.download/DART/DART+Setup+2.0.0.exe Linux : https://s3.amazonaws.com/aptrust.public.download/DART/DART_2.0.0_amd64.deb Double-click the installer after download and follow the prompts on screen. Set Up After installation, DART includes two BagIt profiles by default, one for APTrust and one for DPN. You can use one of these two profiles to create your first job. While jobs can include packaging, validation, and upload operations, you won't be able to upload anything until you've set up a Storage Service to receive an upload. With this, your first job will be limited to creating and validating a BagIt bag. Running Your First Job Follow these steps to create a valid local bag that conforms to the APTrust BagIt profile: Choose Jobs New from the main menu. Drag some files or folders into the files window. To avoid a long-running job that will consume a lot of disk space, choose only a few megabytes of files. Click Next and set the following: Packaging Format : BagIt BagIt Profile : APTrust Package Name : test_bag Output Path : Don't edit this for now. DART will set it for you. Click Next and set the required metadata attributes, which are marked with a red asterisk. For an APTrust bag, these include the Access and Title tags in the aptrust-info.txt file, and the Source-Organization tag in the bag-info.txt file. Click Next to choose the upload targets. Since there will be no available upload targets after initial installtion, Click Next again. The Review and Run screen shows the details of the job you've just defined. Click Run Job to run the job. When the job is complete, you'll find your bag in the Output Path displayed on the Review and Run screen. Further Reading BagIt Profiles describes how to build an customize BagIt profiles, so DART can build bags exactly as you want them. Be sure to read the section on tag default values under Editing a Tag . That will save you from re-entering common tag values, such as Source-Organization, every time you create a new bag. The Dashboard displays information about currently running and recently completed jobs. If you've configured Remote Repository connections, the dashboard can show the status of recent and pending ingests. To get details about what DART is doing, check the Logs . The Settings section describes how to set up upload targets, remote repository connections, and more. Organizations that distribute DART to their members can create Setup Modules to automatically configure DART for their needs. After you've defined and tested a successful job, you can convert it to a Workflow to run other files through the same process.","title":"Getting Started"},{"location":"users/getting_started/#getting-started","text":"DART is the Digital Archivist's Resource Tool. Its primary purpose is to package digital materials and send them off to long-term preservation storage. DART's initial release focuses on packaging materials in BagIt format and uploading them to S3 buckets for ingest in APTrust. DART can be extended through plugins to produce other packaging formats and to communicated via additional network protocols. DART runs in both graphical and command-line modes on Windows, Mac, and Linux.","title":"Getting Started"},{"location":"users/getting_started/#installation","text":"Download the DART installer for your system. Mac : https://s3.amazonaws.com/aptrust.public.download/DART/DART-2.0.0.dmg Windows : https://s3.amazonaws.com/aptrust.public.download/DART/DART+Setup+2.0.0.exe Linux : https://s3.amazonaws.com/aptrust.public.download/DART/DART_2.0.0_amd64.deb Double-click the installer after download and follow the prompts on screen.","title":"Installation"},{"location":"users/getting_started/#set-up","text":"After installation, DART includes two BagIt profiles by default, one for APTrust and one for DPN. You can use one of these two profiles to create your first job. While jobs can include packaging, validation, and upload operations, you won't be able to upload anything until you've set up a Storage Service to receive an upload. With this, your first job will be limited to creating and validating a BagIt bag.","title":"Set Up"},{"location":"users/getting_started/#running-your-first-job","text":"Follow these steps to create a valid local bag that conforms to the APTrust BagIt profile: Choose Jobs New from the main menu. Drag some files or folders into the files window. To avoid a long-running job that will consume a lot of disk space, choose only a few megabytes of files. Click Next and set the following: Packaging Format : BagIt BagIt Profile : APTrust Package Name : test_bag Output Path : Don't edit this for now. DART will set it for you. Click Next and set the required metadata attributes, which are marked with a red asterisk. For an APTrust bag, these include the Access and Title tags in the aptrust-info.txt file, and the Source-Organization tag in the bag-info.txt file. Click Next to choose the upload targets. Since there will be no available upload targets after initial installtion, Click Next again. The Review and Run screen shows the details of the job you've just defined. Click Run Job to run the job. When the job is complete, you'll find your bag in the Output Path displayed on the Review and Run screen.","title":"Running Your First Job"},{"location":"users/getting_started/#further-reading","text":"BagIt Profiles describes how to build an customize BagIt profiles, so DART can build bags exactly as you want them. Be sure to read the section on tag default values under Editing a Tag . That will save you from re-entering common tag values, such as Source-Organization, every time you create a new bag. The Dashboard displays information about currently running and recently completed jobs. If you've configured Remote Repository connections, the dashboard can show the status of recent and pending ingests. To get details about what DART is doing, check the Logs . The Settings section describes how to set up upload targets, remote repository connections, and more. Organizations that distribute DART to their members can create Setup Modules to automatically configure DART for their needs. After you've defined and tested a successful job, you can convert it to a Workflow to run other files through the same process.","title":"Further Reading"},{"location":"users/logs/","text":"Logs DART logs most of its activities as it works. If you're looking for detailed infomation about what DART is doing or has done, or if you want to see detailed error messages, check the logs. The easiest way to view the DART log is to click Help Logs from the menu. This will display a live log window that shows updates as they are written. The About dialog will show the location of the DART log file.","title":"Logs"},{"location":"users/logs/#logs","text":"DART logs most of its activities as it works. If you're looking for detailed infomation about what DART is doing or has done, or if you want to see detailed error messages, check the logs. The easiest way to view the DART log is to click Help Logs from the menu. This will display a live log window that shows updates as they are written. The About dialog will show the location of the DART log file.","title":"Logs"},{"location":"users/scripting/","text":"Scripting with DART The easiest way to script DART jobs is to: Create a workflow . Info If your workflow includes generating bags, you should also create a custom BagIt profile with default values so that your script will only need to create a few bag-specific tag values at runtime. See Customizing BagIt Profiles for more info. Create a simple data object that can be transformed into a JSON structure that matches DART's JobParams object. Pass the JSON to the DART command through STDIN. The examples below show how to do this in Ruby and Python. Note that both examples create the following JSON structure. { workflowName : DART Test Workflow , packageName : test.edu.my_files.tar , files : [ /Users/apd4n/aptrust/dart-docs/site , /Users/apd4n/tmp/logs ], tags : [{ tagFile : bag-info.txt , tagName : Bag-Group-Identifier , userValue : TestGroup_001 }, { tagFile : aptrust-info.txt , tagName : Title , userValue : Workflow Test Files }, { tagFile : aptrust-info.txt , tagName : Description , userValue : Contains miscellaneous files for workflow testing. }] } Example: Ruby To script DART actions, you'll need one simple Ruby class that allows you to define and run a job. You can cut and paste this to get started, but note that you will likely have to change the value of @@dart_command to point to the DART executable on your local machine. require json class Job # Be sure to set this appropriately for your system. # The command npm start is for DART development use only. @@dart_command = npm start attr_accessor :workflow_name , :package_name , :files , :tags def initialize ( workflow_name , package_name ) @workflow_name = workflow_name @package_name = package_name @files = [] @tags = [] end def to_json ( options = {}) { workflowName : workflow_name , packageName : package_name , files : files , tags : tags } . to_json end def add_file ( path ) @files path end def add_tag ( tag_file , tag_name , value ) @tags { tagFile : tag_file , tagName : tag_name , userValue : value } end def run json_string = self . to_json puts json_string puts Starting job opts = { external_encoding : UTF-8 , err : [ :child , :out ] } IO . popen ( #{ @@dart_command } -- --stdin , r+ , opts ) { | pipe | pipe . write json_string + \\n pipe . close_write puts pipe . read } return $? . exitstatus end end Assuming you saved the code above to a file called job.rb , you can create a script like the following to run a job based on a pre-defined DART workflow. require ./job # Create a new job using the DART Test Workflow. # This job will create a tarred bag called test.edu.my_files.tar # in your DART bagging directory. job = Job . new ( DART Test Workflow , test.edu.my_files.tar ) # Add two directories to the list of items that should go into # the bag s payload. Note that you can add a mix of files and # directories. job . add_file ( /Users/apd4n/aptrust/dart-docs/site ) job . add_file ( /Users/apd4n/tmp/logs ) # DART Test Workflow uses a BagIt profile with a number of # preset default values, which are fine for tags like Contact-Email, # which doesn t change from bag to bag. Here we set bag-specific # tag values. job . add_tag ( bag-info.txt , Bag-Group-Identifier , TestGroup_001 ) job . add_tag ( aptrust-info.txt , Title , Workflow Test Files ) job . add_tag ( aptrust-info.txt , Description , Contains miscellaneous files for workflow testing. ) # Run the job and check the exit code. 0 indicates success. # Non-zero values indicate failure. exit_code = job . run () if exit_code == 0 puts Job completed else puts Job failed. Check the DART log for details. end Example: Python The following Python class will help you define and run DART jobs. You can cut and paste this to get started, but note that you will likely have to change the value of dart_command to point to the DART executable on your local machine. import json import sys from subprocess import Popen , PIPE class Job : # Be sure to set this appropriately for your system. # The command npm start is for DART development use only. dart_command = npm start def __init__ ( self , workflow_name , package_name ): self . workflow_name = workflow_name self . package_name = package_name self . files = [] self . tags = [] def add_file ( self , path ): self . files . append ( path ) def add_tag ( self , tag_file , tag_name , value ): self . tags . append ({ tagFile : tag_file , tagName : tag_name , userValue : value }) def to_json ( self ): _dict = { workflowName : self . workflow_name , packageName : self . package_name , files : self . files , tags : self . tags } return json . dumps ( _dict ) def run ( self ): json_string = self . to_json () print ( json_string ) print ( Starting job ) cmd = %s -- --stdin % Job . dart_command child = Popen ( cmd , shell = True , stdin = PIPE , stdout = PIPE , close_fds = True ) stdout_data , stderr_data = child . communicate ( json_string + \\n ) if stdout_data is not None : print ( stdout_data ) if stderr_data is not None : sys . stderr . write ( stderr_data ) return child . returncode Assuming you saved the code above to a file called job.py, you can create a script like the following to run a job based on a pre-defined DART workflow. from job import Job # Create a new job using the DART Test Workflow. # This job will create a tarred bag called test.edu.my_files.tar # in your DART bagging directory. job = Job ( DART Test Workflow , test.edu.my_files.tar ) # Add two directories to the list of items that should go into # the bag s payload. Note that you can add a mix of files and # directories. job . add_file ( /Users/apd4n/aptrust/dart-docs/site ) job . add_file ( /Users/apd4n/tmp/logs ) # DART Test Workflow uses a BagIt profile with a number of # preset default values, which are fine for tags like Contact-Email, # which doesn t change from bag to bag. Here we set bag-specific # tag values. job . add_tag ( bag-info.txt , Bag-Group-Identifier , TestGroup_001 ) job . add_tag ( aptrust-info.txt , Title , Workflow Test Files ) job . add_tag ( aptrust-info.txt , Description , Contains miscellaneous files for workflow testing. ) # Run the job and check the exit code. 0 indicates success. # Non-zero values indicate failure. exit_code = job . run () if exit_code == 0 : print ( Job completed ) else : print ( Job failed. Check the DART log for details. )","title":"Scripting with DART"},{"location":"users/scripting/#scripting-with-dart","text":"The easiest way to script DART jobs is to: Create a workflow . Info If your workflow includes generating bags, you should also create a custom BagIt profile with default values so that your script will only need to create a few bag-specific tag values at runtime. See Customizing BagIt Profiles for more info. Create a simple data object that can be transformed into a JSON structure that matches DART's JobParams object. Pass the JSON to the DART command through STDIN. The examples below show how to do this in Ruby and Python. Note that both examples create the following JSON structure. { workflowName : DART Test Workflow , packageName : test.edu.my_files.tar , files : [ /Users/apd4n/aptrust/dart-docs/site , /Users/apd4n/tmp/logs ], tags : [{ tagFile : bag-info.txt , tagName : Bag-Group-Identifier , userValue : TestGroup_001 }, { tagFile : aptrust-info.txt , tagName : Title , userValue : Workflow Test Files }, { tagFile : aptrust-info.txt , tagName : Description , userValue : Contains miscellaneous files for workflow testing. }] }","title":"Scripting with DART"},{"location":"users/scripting/#example-ruby","text":"To script DART actions, you'll need one simple Ruby class that allows you to define and run a job. You can cut and paste this to get started, but note that you will likely have to change the value of @@dart_command to point to the DART executable on your local machine. require json class Job # Be sure to set this appropriately for your system. # The command npm start is for DART development use only. @@dart_command = npm start attr_accessor :workflow_name , :package_name , :files , :tags def initialize ( workflow_name , package_name ) @workflow_name = workflow_name @package_name = package_name @files = [] @tags = [] end def to_json ( options = {}) { workflowName : workflow_name , packageName : package_name , files : files , tags : tags } . to_json end def add_file ( path ) @files path end def add_tag ( tag_file , tag_name , value ) @tags { tagFile : tag_file , tagName : tag_name , userValue : value } end def run json_string = self . to_json puts json_string puts Starting job opts = { external_encoding : UTF-8 , err : [ :child , :out ] } IO . popen ( #{ @@dart_command } -- --stdin , r+ , opts ) { | pipe | pipe . write json_string + \\n pipe . close_write puts pipe . read } return $? . exitstatus end end Assuming you saved the code above to a file called job.rb , you can create a script like the following to run a job based on a pre-defined DART workflow. require ./job # Create a new job using the DART Test Workflow. # This job will create a tarred bag called test.edu.my_files.tar # in your DART bagging directory. job = Job . new ( DART Test Workflow , test.edu.my_files.tar ) # Add two directories to the list of items that should go into # the bag s payload. Note that you can add a mix of files and # directories. job . add_file ( /Users/apd4n/aptrust/dart-docs/site ) job . add_file ( /Users/apd4n/tmp/logs ) # DART Test Workflow uses a BagIt profile with a number of # preset default values, which are fine for tags like Contact-Email, # which doesn t change from bag to bag. Here we set bag-specific # tag values. job . add_tag ( bag-info.txt , Bag-Group-Identifier , TestGroup_001 ) job . add_tag ( aptrust-info.txt , Title , Workflow Test Files ) job . add_tag ( aptrust-info.txt , Description , Contains miscellaneous files for workflow testing. ) # Run the job and check the exit code. 0 indicates success. # Non-zero values indicate failure. exit_code = job . run () if exit_code == 0 puts Job completed else puts Job failed. Check the DART log for details. end","title":"Example: Ruby"},{"location":"users/scripting/#example-python","text":"The following Python class will help you define and run DART jobs. You can cut and paste this to get started, but note that you will likely have to change the value of dart_command to point to the DART executable on your local machine. import json import sys from subprocess import Popen , PIPE class Job : # Be sure to set this appropriately for your system. # The command npm start is for DART development use only. dart_command = npm start def __init__ ( self , workflow_name , package_name ): self . workflow_name = workflow_name self . package_name = package_name self . files = [] self . tags = [] def add_file ( self , path ): self . files . append ( path ) def add_tag ( self , tag_file , tag_name , value ): self . tags . append ({ tagFile : tag_file , tagName : tag_name , userValue : value }) def to_json ( self ): _dict = { workflowName : self . workflow_name , packageName : self . package_name , files : self . files , tags : self . tags } return json . dumps ( _dict ) def run ( self ): json_string = self . to_json () print ( json_string ) print ( Starting job ) cmd = %s -- --stdin % Job . dart_command child = Popen ( cmd , shell = True , stdin = PIPE , stdout = PIPE , close_fds = True ) stdout_data , stderr_data = child . communicate ( json_string + \\n ) if stdout_data is not None : print ( stdout_data ) if stderr_data is not None : sys . stderr . write ( stderr_data ) return child . returncode Assuming you saved the code above to a file called job.py, you can create a script like the following to run a job based on a pre-defined DART workflow. from job import Job # Create a new job using the DART Test Workflow. # This job will create a tarred bag called test.edu.my_files.tar # in your DART bagging directory. job = Job ( DART Test Workflow , test.edu.my_files.tar ) # Add two directories to the list of items that should go into # the bag s payload. Note that you can add a mix of files and # directories. job . add_file ( /Users/apd4n/aptrust/dart-docs/site ) job . add_file ( /Users/apd4n/tmp/logs ) # DART Test Workflow uses a BagIt profile with a number of # preset default values, which are fine for tags like Contact-Email, # which doesn t change from bag to bag. Here we set bag-specific # tag values. job . add_tag ( bag-info.txt , Bag-Group-Identifier , TestGroup_001 ) job . add_tag ( aptrust-info.txt , Title , Workflow Test Files ) job . add_tag ( aptrust-info.txt , Description , Contains miscellaneous files for workflow testing. ) # Run the job and check the exit code. 0 indicates success. # Non-zero values indicate failure. exit_code = job . run () if exit_code == 0 : print ( Job completed ) else : print ( Job failed. Check the DART log for details. )","title":"Example: Python"},{"location":"users/bagit/","text":"BagIt Profiles While the BagIt specification describes the general requirements for a valid bag, BagIt profiles describe the tags, manifests, and tag manifests required to make a valid bag for a specific organization or purpose. DART uses BagIt profiles to produce bags that adhere to a profile, and to validate that bags do adhere to the profile. DART BagIt Profiles While the general specification for BagIt Profiles can be found on GitHub , DART's BagIt profiles differ from the published specification in the following ways: DART profiles use camel case identifiers with no hyphens or periods in attribute names. For example, the Allow-Fetch.txt in GitHub BagIt profiles is called allowFetchTxt in DART profiles. This is in part to simplify JavaScript attributes so they can be reference in dot notation, and in part because the nedb object database used in early versions of DART did not support attribute names containing dots. DART profiles include an id attribute with a UUID. This is used internally, while externally the bagItProfileIdentifier URL is used externally. DART profiles include the following additional boolean attributes: allowMiscTopLevelFiles which indicates whether files other than manifests and tag manifests are allowed in the bag's root directory. allowMiscDirectories which indicates whether directories other than /data and its children are allowed in the bag. tarDirMustMatchName which indicates whether the name of the unserialized bag must match the name of the serialized bag, minus the serialization extension. (That is, whether my_bag.tar must untar to my_bag, and my_bag.zip must unzip to my_bag.) DART includes the attribute baseProfileId for internal use, to know whether a user-created profile was based on an existing profile. DART includes the isBuiltIn attribute to indicate that a profile was built in to the application (usually through a setup module or migration). These profiles cannot be deleted. DART does not specify tagFilesRequired or tagFilesAllowed . DART BagIt profiles specify all tag requirements in a single list called tags while the GitHub BagIt spec defines them as nested objects with arbitrary names. The single list of uniform objects in the DART model makes tag definitions easier to manipulate. While tag definitions in the GitHub BagIt Profile spec include only the attributes required and values , DART tag definitions include the following attributes: id - A unique identifier in UUID format that DART uses internally. This allows users to edit tag definitions in the DART UI without the system losing track of which tag is being edited. The UUID is immutable while all other attributes are not. tagFile - The name of the tag file that contains the tag. This is a path relative to the bag root. For example, bag-info.txt or custom-tags/image-credits.txt . tagName - The name of the tag. For example, Source-Organization . required - A boolean indicating whether the tag is required. values - An option list of legal values. If this list is present and a tag contains a value that's not in the list, the value and the bag are invalid. defaultValue - A default value assigned by the user to the tag. DART's BagIt Profile editor allows users to specify default values to tags that will be consistent across bags. For example, users can define a default value to Source-Organization so they don't have to assign it repeatedly every time they create a new bag. userValue - The value of a tag to be written into or read from a tag file. Users can specify a userValue that overrides the defaultValue when they create a bag. When reading a bag, DART assigns the actual value of a tag to what was read from the bag. isBuiltIn - A boolean value indicating whether a tag definition is built in (as opposed to user-created). DART's BagIt Profile editor allows users to add custom tags to a published profile, such as the APTrust profile, while preventing them from deleting built-in tag definitions. Deleting a built-in tag definition such as Source-Organization would lead to DART generating invalid bags. help - Help text to describe the significance of the tag to the user. If present, the DART UI will display this message for the user's edification and delight. Built-in Profiles DART includes the following built-in profiles. Note that the BagIt Profile editor allows you to clone and customize each of these, though customization is limited to adding tags and tag files, and setting default tag values. APTrust - The standard APTrust BagIt profile. BTR - The Beyond the Repository BagIt profile, which will be accepted by a number of distributed digital preservation repositories. (Coming later in 2019.) DPN - The legacy DPN BagIt profile. This is used primarily for testing and development. Custom Profiles DART enables users to create new BagIt profiles from scratch, and to clone and modify existing profiles. See also: Creating BagIt Profiles , Customizing BagIt Profiles","title":"BagIt Profiles"},{"location":"users/bagit/#bagit-profiles","text":"While the BagIt specification describes the general requirements for a valid bag, BagIt profiles describe the tags, manifests, and tag manifests required to make a valid bag for a specific organization or purpose. DART uses BagIt profiles to produce bags that adhere to a profile, and to validate that bags do adhere to the profile.","title":"BagIt Profiles"},{"location":"users/bagit/#dart-bagit-profiles","text":"While the general specification for BagIt Profiles can be found on GitHub , DART's BagIt profiles differ from the published specification in the following ways: DART profiles use camel case identifiers with no hyphens or periods in attribute names. For example, the Allow-Fetch.txt in GitHub BagIt profiles is called allowFetchTxt in DART profiles. This is in part to simplify JavaScript attributes so they can be reference in dot notation, and in part because the nedb object database used in early versions of DART did not support attribute names containing dots. DART profiles include an id attribute with a UUID. This is used internally, while externally the bagItProfileIdentifier URL is used externally. DART profiles include the following additional boolean attributes: allowMiscTopLevelFiles which indicates whether files other than manifests and tag manifests are allowed in the bag's root directory. allowMiscDirectories which indicates whether directories other than /data and its children are allowed in the bag. tarDirMustMatchName which indicates whether the name of the unserialized bag must match the name of the serialized bag, minus the serialization extension. (That is, whether my_bag.tar must untar to my_bag, and my_bag.zip must unzip to my_bag.) DART includes the attribute baseProfileId for internal use, to know whether a user-created profile was based on an existing profile. DART includes the isBuiltIn attribute to indicate that a profile was built in to the application (usually through a setup module or migration). These profiles cannot be deleted. DART does not specify tagFilesRequired or tagFilesAllowed . DART BagIt profiles specify all tag requirements in a single list called tags while the GitHub BagIt spec defines them as nested objects with arbitrary names. The single list of uniform objects in the DART model makes tag definitions easier to manipulate. While tag definitions in the GitHub BagIt Profile spec include only the attributes required and values , DART tag definitions include the following attributes: id - A unique identifier in UUID format that DART uses internally. This allows users to edit tag definitions in the DART UI without the system losing track of which tag is being edited. The UUID is immutable while all other attributes are not. tagFile - The name of the tag file that contains the tag. This is a path relative to the bag root. For example, bag-info.txt or custom-tags/image-credits.txt . tagName - The name of the tag. For example, Source-Organization . required - A boolean indicating whether the tag is required. values - An option list of legal values. If this list is present and a tag contains a value that's not in the list, the value and the bag are invalid. defaultValue - A default value assigned by the user to the tag. DART's BagIt Profile editor allows users to specify default values to tags that will be consistent across bags. For example, users can define a default value to Source-Organization so they don't have to assign it repeatedly every time they create a new bag. userValue - The value of a tag to be written into or read from a tag file. Users can specify a userValue that overrides the defaultValue when they create a bag. When reading a bag, DART assigns the actual value of a tag to what was read from the bag. isBuiltIn - A boolean value indicating whether a tag definition is built in (as opposed to user-created). DART's BagIt Profile editor allows users to add custom tags to a published profile, such as the APTrust profile, while preventing them from deleting built-in tag definitions. Deleting a built-in tag definition such as Source-Organization would lead to DART generating invalid bags. help - Help text to describe the significance of the tag to the user. If present, the DART UI will display this message for the user's edification and delight.","title":"DART BagIt Profiles"},{"location":"users/bagit/#built-in-profiles","text":"DART includes the following built-in profiles. Note that the BagIt Profile editor allows you to clone and customize each of these, though customization is limited to adding tags and tag files, and setting default tag values. APTrust - The standard APTrust BagIt profile. BTR - The Beyond the Repository BagIt profile, which will be accepted by a number of distributed digital preservation repositories. (Coming later in 2019.) DPN - The legacy DPN BagIt profile. This is used primarily for testing and development.","title":"Built-in Profiles"},{"location":"users/bagit/#custom-profiles","text":"DART enables users to create new BagIt profiles from scratch, and to clone and modify existing profiles. See also: Creating BagIt Profiles , Customizing BagIt Profiles","title":"Custom Profiles"},{"location":"users/bagit/creating/","text":"Creating Profiles To create a new BagIt Profile: Choose Settings BagIt Profiles from the menu. Click the New button at the top of the profiles list. Select an option from the Base Profile list. Chose None if you want to create a new profile from scratch. Choose the name of an existing profile if you want to clone and modify an existing profile. Click the Create button. Note Cloning an existing BagIt profile can be useful if you're going to create bags on behalf of more than one organization or group. You can set different default values for tags such as Source-Organization or Contact-Email within each cloned profile, and then assign meaningful names such as APTrust Profile for Law Library and APTrust Profile for Engineering Library . Once you've created a new BagIt profile, you'll want to customize it using the built-in BagIt profile editor. See also: Customizing BagIt Profiles","title":"Creating Profiles"},{"location":"users/bagit/creating/#creating-profiles","text":"To create a new BagIt Profile: Choose Settings BagIt Profiles from the menu. Click the New button at the top of the profiles list. Select an option from the Base Profile list. Chose None if you want to create a new profile from scratch. Choose the name of an existing profile if you want to clone and modify an existing profile. Click the Create button. Note Cloning an existing BagIt profile can be useful if you're going to create bags on behalf of more than one organization or group. You can set different default values for tags such as Source-Organization or Contact-Email within each cloned profile, and then assign meaningful names such as APTrust Profile for Law Library and APTrust Profile for Engineering Library . Once you've created a new BagIt profile, you'll want to customize it using the built-in BagIt profile editor. See also: Customizing BagIt Profiles","title":"Creating Profiles"},{"location":"users/bagit/customizing/","text":"Customizing Profiles To customize a BagIt profile, click the name of the profile in the profiles list, or click new and follow the steps to create a BagIt profile . About The About tab of the BagIt profile editor enables you to set a name and description for your profile. Info The Info tab includes fields to edit the BagIt-Profile-Info section of the profile. This includes the profile's URL identifier. General The General tab includes information about which BagIt versions your profile accepts, whether to allow fetch.txt files, and whether to allow miscellaneous top level files (arbitrary tag files directly under the root directory) and miscellaneous directories outside the payload (/data) directory. Manifests The Manifests tab specifies which manifests and tag manifests your profile requires. You can select multiple options from each list by holding down the Control key on Windows or the Command key on Mac while you click. Serialization The Serialization tab allows you to specify whether serialization is required, optional, or forbidden, as well as which serialization formats are supported. You can also specify here whether serialized bags must deserialize to a directory whose name matches the serialized file name. (For example, my_bag.tar must untar to my_bag and my_bag.zip must unzip to my_bag.) Tag Files The Tag Files tab includes a drop-down list for editing the profile's tag files, and for adding new tag files. Adding a New Tag File To add a new tag file: Click Add New Tag File on the drop-down list. Enter a name for the tag file. If the name includes slashes, the tag file will be created in a subdirectory beneath the bag's root directory. For example, custom-tags/photo-credits.txt would be placed in the bag's custom-tags directory. Click the Save button. Editing a Tag File To edit a tag file: Click the Tag Files tab. Select the name of the file you want to edit. Adding a Tag To add a tag to a tag file, click the New Tag button (visible in the screenshot above), then follow the steps in Editing a Tag below. Editing a Tag To edit a tag: Click the name of the tag you want to edit. Set the appropriate values in the dialog. Tag Name - The name of the tag. This is required. Required - A Yes/No value indicating whether the tag must have a value for the bag to be considered valid. Values - An optional list of allowed values for this tag. Default Value - An optional default value for this tag. Help - An optional help message. This message will be displayed to users who are filling out a bag's tag values in DART. Click the Save button. Deleting a Tag To delete a tag, click the red X to the right of the tag name in the tag list view. If the tag does not have a red X, it is a required tag from a published profile and cannot be deleted. When you delete the last tag of a tag file, DART deletes the tag file as well. Deleting a Tag File To delete a tag file, delete all of the tags in the file. See Deleting a Tag above.","title":"Customizing Profiles"},{"location":"users/bagit/customizing/#customizing-profiles","text":"To customize a BagIt profile, click the name of the profile in the profiles list, or click new and follow the steps to create a BagIt profile .","title":"Customizing Profiles"},{"location":"users/bagit/customizing/#about","text":"The About tab of the BagIt profile editor enables you to set a name and description for your profile.","title":"About"},{"location":"users/bagit/customizing/#info","text":"The Info tab includes fields to edit the BagIt-Profile-Info section of the profile. This includes the profile's URL identifier.","title":"Info"},{"location":"users/bagit/customizing/#general","text":"The General tab includes information about which BagIt versions your profile accepts, whether to allow fetch.txt files, and whether to allow miscellaneous top level files (arbitrary tag files directly under the root directory) and miscellaneous directories outside the payload (/data) directory.","title":"General"},{"location":"users/bagit/customizing/#manifests","text":"The Manifests tab specifies which manifests and tag manifests your profile requires. You can select multiple options from each list by holding down the Control key on Windows or the Command key on Mac while you click.","title":"Manifests"},{"location":"users/bagit/customizing/#serialization","text":"The Serialization tab allows you to specify whether serialization is required, optional, or forbidden, as well as which serialization formats are supported. You can also specify here whether serialized bags must deserialize to a directory whose name matches the serialized file name. (For example, my_bag.tar must untar to my_bag and my_bag.zip must unzip to my_bag.)","title":"Serialization"},{"location":"users/bagit/customizing/#tag-files","text":"The Tag Files tab includes a drop-down list for editing the profile's tag files, and for adding new tag files.","title":"Tag Files"},{"location":"users/bagit/customizing/#adding-a-new-tag-file","text":"To add a new tag file: Click Add New Tag File on the drop-down list. Enter a name for the tag file. If the name includes slashes, the tag file will be created in a subdirectory beneath the bag's root directory. For example, custom-tags/photo-credits.txt would be placed in the bag's custom-tags directory. Click the Save button.","title":"Adding a New Tag File"},{"location":"users/bagit/customizing/#editing-a-tag-file","text":"To edit a tag file: Click the Tag Files tab. Select the name of the file you want to edit.","title":"Editing a Tag File"},{"location":"users/bagit/customizing/#adding-a-tag","text":"To add a tag to a tag file, click the New Tag button (visible in the screenshot above), then follow the steps in Editing a Tag below.","title":"Adding a Tag"},{"location":"users/bagit/customizing/#editing-a-tag","text":"To edit a tag: Click the name of the tag you want to edit. Set the appropriate values in the dialog. Tag Name - The name of the tag. This is required. Required - A Yes/No value indicating whether the tag must have a value for the bag to be considered valid. Values - An optional list of allowed values for this tag. Default Value - An optional default value for this tag. Help - An optional help message. This message will be displayed to users who are filling out a bag's tag values in DART. Click the Save button.","title":"Editing a Tag"},{"location":"users/bagit/customizing/#deleting-a-tag","text":"To delete a tag, click the red X to the right of the tag name in the tag list view. If the tag does not have a red X, it is a required tag from a published profile and cannot be deleted. When you delete the last tag of a tag file, DART deletes the tag file as well.","title":"Deleting a Tag"},{"location":"users/bagit/customizing/#deleting-a-tag-file","text":"To delete a tag file, delete all of the tags in the file. See Deleting a Tag above.","title":"Deleting a Tag File"},{"location":"users/bagit/exporting/","text":"Exporting Profiles This feature isn't implemented yet. It will allow users to export DART BagIt profiles to standard BagIt Profiles as defined in this GitHub repo .","title":"Exporting Profiles"},{"location":"users/bagit/exporting/#exporting-profiles","text":"This feature isn't implemented yet. It will allow users to export DART BagIt profiles to standard BagIt Profiles as defined in this GitHub repo .","title":"Exporting Profiles"},{"location":"users/bagit/importing/","text":"Importing Profiles This feature isn't implemented yet. Currently, the only ways to get profiles into DART are: migrations setup modules creating your own through the UI","title":"Importing Profiles"},{"location":"users/bagit/importing/#importing-profiles","text":"This feature isn't implemented yet. Currently, the only ways to get profiles into DART are: migrations setup modules creating your own through the UI","title":"Importing Profiles"},{"location":"users/jobs/","text":"Jobs A job is a set of actions that may include one or more of the following: Packaging a number of files into a defined format, such as BagIt, tar, etc. Validating the package. Uploading the package to one or more remote locations. DART was initially designed for APTrust depositors to bag files according to the APTrust BagIt profile, validate the bags, and then send them to an S3 bucket for ingest into APTrust's preservation repository. DART plugin architecture will allow it to handle similary patterned jobs that use different packaging formats and network protocols such as zip, rar, or parchive formats sent via FTP or rsync. The process for creating and running jobs invlolves these steps: Adding files . Choosing a package format . Adding metadata . Choosing upload targets . Reviewing and running the job . For infomation about developing DART plugins, see the Plugins Developer Documentation . Jobs and Workflows Jobs can be converted to workflows. A workflow is essentially a job template that can be run in the DART UI or from the command line. A workflow enables you to run a number of jobs that all follow the same pattern (same packaging format, same default metadata values, and same upload targets).","title":"Jobs"},{"location":"users/jobs/#jobs","text":"A job is a set of actions that may include one or more of the following: Packaging a number of files into a defined format, such as BagIt, tar, etc. Validating the package. Uploading the package to one or more remote locations. DART was initially designed for APTrust depositors to bag files according to the APTrust BagIt profile, validate the bags, and then send them to an S3 bucket for ingest into APTrust's preservation repository. DART plugin architecture will allow it to handle similary patterned jobs that use different packaging formats and network protocols such as zip, rar, or parchive formats sent via FTP or rsync. The process for creating and running jobs invlolves these steps: Adding files . Choosing a package format . Adding metadata . Choosing upload targets . Reviewing and running the job . For infomation about developing DART plugins, see the Plugins Developer Documentation .","title":"Jobs"},{"location":"users/jobs/#jobs-and-workflows","text":"Jobs can be converted to workflows. A workflow is essentially a job template that can be run in the DART UI or from the command line. A workflow enables you to run a number of jobs that all follow the same pattern (same packaging format, same default metadata values, and same upload targets).","title":"Jobs and Workflows"},{"location":"users/jobs/delete/","text":"Deleting Jobs To delete a job: Choose Jobs List from the menu. Click on the job you want to delete. Click the red Delete button in the bottom left corner of the Job files page.","title":"Deleting Jobs"},{"location":"users/jobs/delete/#deleting-jobs","text":"To delete a job: Choose Jobs List from the menu. Click on the job you want to delete. Click the red Delete button in the bottom left corner of the Job files page.","title":"Deleting Jobs"},{"location":"users/jobs/files/","text":"Adding Files After you create a new job or click on a job in the Jobs list, you'll see the files page. You can add files to a job by dragging them into the drop zone, which is outlined in blue. The files window shows the total number of files and directories you've added, and total size of all the files. After adding files and directories, click the Next button to move on to the Packaging step. Note that you can also delete the job from this screen. Removing Files To remove a file from the job, click the red X in the row of the file you want to delete.","title":"Adding Files"},{"location":"users/jobs/files/#adding-files","text":"After you create a new job or click on a job in the Jobs list, you'll see the files page. You can add files to a job by dragging them into the drop zone, which is outlined in blue. The files window shows the total number of files and directories you've added, and total size of all the files. After adding files and directories, click the Next button to move on to the Packaging step. Note that you can also delete the job from this screen.","title":"Adding Files"},{"location":"users/jobs/files/#removing-files","text":"To remove a file from the job, click the red X in the row of the file you want to delete.","title":"Removing Files"},{"location":"users/jobs/list/","text":"Listing Jobs To list all jobs, Choose Jobs List from the menu. The list shows the job name and information about when it was last packaged, validated, and/or uploaded. Click on any job in the list to view it. On the following screen, you'll be able to edit or delete the job.","title":"Listing Jobs"},{"location":"users/jobs/list/#listing-jobs","text":"To list all jobs, Choose Jobs List from the menu. The list shows the job name and information about when it was last packaged, validated, and/or uploaded. Click on any job in the list to view it. On the following screen, you'll be able to edit or delete the job.","title":"Listing Jobs"},{"location":"users/jobs/metadata/","text":"Metadata You'll see the job metadata screen if you chose the BagIt packaging format on the previous screen. This screen allows you to enter values for tags that will go into BagIt tag files. By default, this screen only shows tags whose values are not already filled in by default values. Default values come from two places: Default tag values you've entered into your local BagIt profiles. See the Editing a Tag section for information about setting default values. Auto-filled values calculated by DART when it creates the bag, such as the Payload-Oxum, Bagging-Software, and Bagging-Date. If you want to edit tags with pre-set default values, click the Show All Tags button in the top right corner of the page. Adding Custom Tags You can add a custom tag to a bag by clicking the Add New Tag button at the top of the page. Note that adding extra tags to a bag generally will not cause the bag to be invalid. The only exception to this rule is adding tags that the BagIt specification says may not be repeated, such as the Payload-Oxum tag.","title":"Metadata"},{"location":"users/jobs/metadata/#metadata","text":"You'll see the job metadata screen if you chose the BagIt packaging format on the previous screen. This screen allows you to enter values for tags that will go into BagIt tag files. By default, this screen only shows tags whose values are not already filled in by default values. Default values come from two places: Default tag values you've entered into your local BagIt profiles. See the Editing a Tag section for information about setting default values. Auto-filled values calculated by DART when it creates the bag, such as the Payload-Oxum, Bagging-Software, and Bagging-Date. If you want to edit tags with pre-set default values, click the Show All Tags button in the top right corner of the page.","title":"Metadata"},{"location":"users/jobs/metadata/#adding-custom-tags","text":"You can add a custom tag to a bag by clicking the Add New Tag button at the top of the page. Note that adding extra tags to a bag generally will not cause the bag to be invalid. The only exception to this rule is adding tags that the BagIt specification says may not be repeated, such as the Payload-Oxum tag.","title":"Adding Custom Tags"},{"location":"users/jobs/packaging/","text":"Packaging The packaging screen incudes the following options: Package Format - Choose how you want your files to be packaged. The following options are available: None - Choose this option if you don't want to package your files at all. This option makes sense when you want upload files without first bagging or tarring them. BagIt - Choose this if you want to bag your files in BagIt format. Directory - Choose if you want to copy all of your files into a single directory. This will not move or delete the original files. Tar - Choose this if you want to pack your files into a single tar file. BagIt Profile - This option appears when you choose BagIt as the package format. Note that you can have structurally identical BagIt profiles with different sets of default values. See Creating BagIt Profiles for more information. Package Name - Type the name of the package you want to create. DART will create a package with this file name. Note that some repositories, including APTrust * , have required naming conventions, and most discourage the use of non-printable characters in package names. Output Path - This is where DART will put the local copy of the package that it builds. Notice that this field is filled in automatically as you type the package name. Unless you have good reason, you should not manually edit this field. * APTrust bag names should begin with your organization identifier, followed by a dot and a unique name. For example, virginia.edu.photos-2019-07-21.","title":"Packaging"},{"location":"users/jobs/packaging/#packaging","text":"The packaging screen incudes the following options: Package Format - Choose how you want your files to be packaged. The following options are available: None - Choose this option if you don't want to package your files at all. This option makes sense when you want upload files without first bagging or tarring them. BagIt - Choose this if you want to bag your files in BagIt format. Directory - Choose if you want to copy all of your files into a single directory. This will not move or delete the original files. Tar - Choose this if you want to pack your files into a single tar file. BagIt Profile - This option appears when you choose BagIt as the package format. Note that you can have structurally identical BagIt profiles with different sets of default values. See Creating BagIt Profiles for more information. Package Name - Type the name of the package you want to create. DART will create a package with this file name. Note that some repositories, including APTrust * , have required naming conventions, and most discourage the use of non-printable characters in package names. Output Path - This is where DART will put the local copy of the package that it builds. Notice that this field is filled in automatically as you type the package name. Unless you have good reason, you should not manually edit this field. * APTrust bag names should begin with your organization identifier, followed by a dot and a unique name. For example, virginia.edu.photos-2019-07-21.","title":"Packaging"},{"location":"users/jobs/run/","text":"Run Your Job After defining the files your job will work with and the optional packaging, metadata, and upload steps, the Run page displays a summary of the work that DART will perform. Review the details to ensure that everything looks right, then click the Run button to run the job. After clicking run, your job will begin. DART runs each job in a separate process, which provides a number of benefits: You can run many jobs at once. If any job encounters errors, it will not affect the other running jobs. You can continue to use DART while background jobs run. Nothing you do in DART, except quitting the application, will affect the running jobs. After clicking Run , you'll see the progress of each operation on screen. Striped blue bars indicate a work in progress. A green bar represents a completed operation, while a red bar indicates a failure. If a job includes multiple uploads, you'll see one progress bar for each upload. Large jobs may take a long time to complete. As long as jobs are running, you can continue to work in DART without affecting their progress. You'll see a badge like this in the upper right corner of the menu showing the number of running background jobs: Progress Bar Accuracy The progress bars for packaging and validation are accurate to within a few seconds of actual operation time. The progress bar for uploads usually displays more progress than has actually been completed. This is because DART can know exactly how many bytes of an upload it has prepared to send, but not how many the upload target has received. The upload progress bar displays the number of bytes prepared, and will appear to stall at around 98% completion on large uploads, as it awaits transferral of the final chunk of data. In a 100 MB upload, that final chunk may include only 1 MB of data, taking a few seconds to transfer. In a 5 TB upload to S3, the final chunk can be 535 MB and can take many minutes to complete. Creating a Workflow from a Job If you've created a successful job that you want to be the pattern for future jobs, click the Create Workflow button to create a repeatable workflow that can run new files through the same set of steps that this job just completed.","title":"Run Your Job"},{"location":"users/jobs/run/#run-your-job","text":"After defining the files your job will work with and the optional packaging, metadata, and upload steps, the Run page displays a summary of the work that DART will perform. Review the details to ensure that everything looks right, then click the Run button to run the job. After clicking run, your job will begin. DART runs each job in a separate process, which provides a number of benefits: You can run many jobs at once. If any job encounters errors, it will not affect the other running jobs. You can continue to use DART while background jobs run. Nothing you do in DART, except quitting the application, will affect the running jobs. After clicking Run , you'll see the progress of each operation on screen. Striped blue bars indicate a work in progress. A green bar represents a completed operation, while a red bar indicates a failure. If a job includes multiple uploads, you'll see one progress bar for each upload. Large jobs may take a long time to complete. As long as jobs are running, you can continue to work in DART without affecting their progress. You'll see a badge like this in the upper right corner of the menu showing the number of running background jobs:","title":"Run Your Job"},{"location":"users/jobs/run/#progress-bar-accuracy","text":"The progress bars for packaging and validation are accurate to within a few seconds of actual operation time. The progress bar for uploads usually displays more progress than has actually been completed. This is because DART can know exactly how many bytes of an upload it has prepared to send, but not how many the upload target has received. The upload progress bar displays the number of bytes prepared, and will appear to stall at around 98% completion on large uploads, as it awaits transferral of the final chunk of data. In a 100 MB upload, that final chunk may include only 1 MB of data, taking a few seconds to transfer. In a 5 TB upload to S3, the final chunk can be 535 MB and can take many minutes to complete.","title":"Progress Bar Accuracy"},{"location":"users/jobs/run/#creating-a-workflow-from-a-job","text":"If you've created a successful job that you want to be the pattern for future jobs, click the Create Workflow button to create a repeatable workflow that can run new files through the same set of steps that this job just completed.","title":"Creating a Workflow from a Job"},{"location":"users/jobs/upload/","text":"Uploads You can specify one or more upload targets on the uploads page. Simply check the box beside each target you want to upload to. The list of available targets comes from the Storage Service settings in your local DART installation. You can add as many storage services as you like. To appear in the list of upload targets, a storage service must include a protocol, URL, login, and password, and it must have the Allows Upload set to Yes . If some of your storage services do not appear in the list, check to see they meet all of these criteria.","title":"Uploads"},{"location":"users/jobs/upload/#uploads","text":"You can specify one or more upload targets on the uploads page. Simply check the box beside each target you want to upload to. The list of available targets comes from the Storage Service settings in your local DART installation. You can add as many storage services as you like. To appear in the list of upload targets, a storage service must include a protocol, URL, login, and password, and it must have the Allows Upload set to Yes . If some of your storage services do not appear in the list, check to see they meet all of these criteria.","title":"Uploads"},{"location":"users/settings/","text":"Settings DART includes the following settings: App Settings include information such as your organization name (used when creating bags) and your default output directory (to which bags are written). Internal Settings are read-only settings that you may occasionally need to examine when tracing problems. Remote Repositories describe how to connect to remote preservation repositories that ingest the materials you upload. Storage Services describe how to connect to drop-off and pick up points, such as S3 buckets or FTP services. These are usually temporary storage points used to drop off materials for ingest or to pick up items restored by a preservation repository.","title":"Settings"},{"location":"users/settings/#settings","text":"DART includes the following settings: App Settings include information such as your organization name (used when creating bags) and your default output directory (to which bags are written). Internal Settings are read-only settings that you may occasionally need to examine when tracing problems. Remote Repositories describe how to connect to remote preservation repositories that ingest the materials you upload. Storage Services describe how to connect to drop-off and pick up points, such as S3 buckets or FTP services. These are usually temporary storage points used to drop off materials for ingest or to pick up items restored by a preservation repository.","title":"Settings"},{"location":"users/settings/app_settings/","text":"App Settings App Settings contain DART's application-wide settings. These may be used when creating bags and other packages. To view the list of all settings, select Settings App Settings from the main menu. Editing App Settings Click on any setting in the list to edit it. Note that some essential settings, such as Bagging Directory and Institution Domain cannot be renamed or deleted, though their values can be changed.","title":"App Settings"},{"location":"users/settings/app_settings/#app-settings","text":"App Settings contain DART's application-wide settings. These may be used when creating bags and other packages. To view the list of all settings, select Settings App Settings from the main menu.","title":"App Settings"},{"location":"users/settings/app_settings/#editing-app-settings","text":"Click on any setting in the list to edit it. Note that some essential settings, such as Bagging Directory and Institution Domain cannot be renamed or deleted, though their values can be changed.","title":"Editing App Settings"},{"location":"users/settings/internal_settings/","text":"Internal Settings Internal Settings contain configuration information that users cannot edit. These settings are created by plugins, setup packages, and software updates. Though you cannot change them, knowing their values may be helpful to DART users and developers.","title":"Internal Settings"},{"location":"users/settings/internal_settings/#internal-settings","text":"Internal Settings contain configuration information that users cannot edit. These settings are created by plugins, setup packages, and software updates. Though you cannot change them, knowing their values may be helpful to DART users and developers.","title":"Internal Settings"},{"location":"users/settings/plugins/","text":"Plugins DART plugins provide features such as the following: Format Reader - Allows DART to read files packaged in a certain format, such as tar. Format Writer - Allows DART to write files into specific formats, such as tar. Network Client - Allows DART to communicate via certain network protocols, such as S3, so that it can upload and/or download files. Repository - Allows DART to communicate with remote repositories to retrieve information such as a list of ingested objects. Setup - These plugins allow organizations to automatically apply common configuration settings for their users. To see the list of plugins installed on your system, choose Settings Plugins from the menu. You should see a list like this: See also: Plugins documentation for developers","title":"Plugins"},{"location":"users/settings/plugins/#plugins","text":"DART plugins provide features such as the following: Format Reader - Allows DART to read files packaged in a certain format, such as tar. Format Writer - Allows DART to write files into specific formats, such as tar. Network Client - Allows DART to communicate via certain network protocols, such as S3, so that it can upload and/or download files. Repository - Allows DART to communicate with remote repositories to retrieve information such as a list of ingested objects. Setup - These plugins allow organizations to automatically apply common configuration settings for their users. To see the list of plugins installed on your system, choose Settings Plugins from the menu. You should see a list like this: See also: Plugins documentation for developers","title":"Plugins"},{"location":"users/settings/remote_repositories/","text":"Remote Repositories Remote repositories are services to which you upload data for preservation. DART can query remote repositories to show the status of items you've uploaded for ingest, provided the following three conditions are met: The remote repository has a REST API. Most do, including APTrust, Fedora, DSpace, and many others. DART has a plugin that knows how to talk to the repository. (On initial release, the only plugin is for APTrust, but more may be coming.) You have a Remote Repository setting that points to the correct URL and contains valid login credentials. Listing Remote Repositories To view the list of Remote Repository settings, choose Settings Remote Repositories from the menu. Editing Remote Repositories Click on any repository in the list to edit it, or click the New button to create a new one. Description of Settings Name The name of the remote repository. This is required. It can be anything you want, and chaning it will not affect the behavior or availability of the repository. URL The base URL of the repository's REST API. This may or may not include path information. For example, https://example.com has no path information, while https://example.com/api/v2/ does include path info. Check with your repository to get the correct URL. Plugin Choose the plugin that can connect to your repository. If you don't see the plugin in the list, it has not been installed. Note that at the time of DART's initial release, the only available plugin is APTrustClient . User ID Enter the user ID you use to connect to the repository's REST API. If the API only uses a token and no user ID, leave this blank. API Token Enter the API token used to connect to this repository. You'll have to get a token from the repository itself. Login Extra This field is generally left blank. If your repository uses it, they should provide instructions on how to fill this in.","title":"Remote Repositories"},{"location":"users/settings/remote_repositories/#remote-repositories","text":"Remote repositories are services to which you upload data for preservation. DART can query remote repositories to show the status of items you've uploaded for ingest, provided the following three conditions are met: The remote repository has a REST API. Most do, including APTrust, Fedora, DSpace, and many others. DART has a plugin that knows how to talk to the repository. (On initial release, the only plugin is for APTrust, but more may be coming.) You have a Remote Repository setting that points to the correct URL and contains valid login credentials.","title":"Remote Repositories"},{"location":"users/settings/remote_repositories/#listing-remote-repositories","text":"To view the list of Remote Repository settings, choose Settings Remote Repositories from the menu.","title":"Listing Remote Repositories"},{"location":"users/settings/remote_repositories/#editing-remote-repositories","text":"Click on any repository in the list to edit it, or click the New button to create a new one.","title":"Editing Remote Repositories"},{"location":"users/settings/remote_repositories/#description-of-settings","text":"","title":"Description of Settings"},{"location":"users/settings/remote_repositories/#name","text":"The name of the remote repository. This is required. It can be anything you want, and chaning it will not affect the behavior or availability of the repository.","title":"Name"},{"location":"users/settings/remote_repositories/#url","text":"The base URL of the repository's REST API. This may or may not include path information. For example, https://example.com has no path information, while https://example.com/api/v2/ does include path info. Check with your repository to get the correct URL.","title":"URL"},{"location":"users/settings/remote_repositories/#plugin","text":"Choose the plugin that can connect to your repository. If you don't see the plugin in the list, it has not been installed. Note that at the time of DART's initial release, the only available plugin is APTrustClient .","title":"Plugin"},{"location":"users/settings/remote_repositories/#user-id","text":"Enter the user ID you use to connect to the repository's REST API. If the API only uses a token and no user ID, leave this blank.","title":"User ID"},{"location":"users/settings/remote_repositories/#api-token","text":"Enter the API token used to connect to this repository. You'll have to get a token from the repository itself.","title":"API Token"},{"location":"users/settings/remote_repositories/#login-extra","text":"This field is generally left blank. If your repository uses it, they should provide instructions on how to fill this in.","title":"Login Extra"},{"location":"users/settings/storage_services/","text":"Storage Services Storage services are not repositories! They are pickup and drop-off points for materials going into or coming out of repositories. Some repositories ask depositors to upload materials into an S3 bucket or an SFTP folder for ingest, and restore materials to a similar bucket or folder for depositors to retrieve. Storage services allow DART to connect to these pickup and drop-off points. Note, however, that you're free to send data to and from these storage services even if they're not ultimately bound for a preservation repository. Listing Storage Services To list all storage services, choose Settings Storage Services from the menu. Editing Storage Services Click any storage servicei in the list to edit it. Description of Settings Name The name of the service. Choose a name that's meaningful to you and that differentiates this service from others. You can change the name at any time without affecting the bevavior or availability of the service. Description A description of this service. Protocol Choose the network protocol used to communicate with this service. Note: At launch, DART supports only the S3 protocol. Host Enter the name or IP address of the service host. Do not include protocol prefixes like https:// or ftp:// . For example, the host name for Amazon's S3 service is s3.amazonaws.com . A locally hosted service may be s3.example.com or ftp.example.com . You can also enter an IP address here such as 127.0.0.1 . Port The port to connect to. In most cases, you'll want to leave this at 0 (zero). Set this only if the service is running on a non-standard port number. Bucket The name of the bucket you'll be uploading into or downloading from on the remote host. For the S3 protocol, this will be a bucket name like aptrust.dart.test . For protocols like FTP and rsync, this will be a directory name like uploads/ingest/ or downloads/restore . Allows Upload Choose Yes if this service allows you to upload files, No otherwise. Info This setting is important. When you run a job, DART gives you a choice of storage services to which to send your files. DART will show only those services where Allows Upload is set to Yes . Allows Download Choose Yes if this service allows you to download files, No otherwise. Info While DART does not support downloads in its initial release, it may support them in a future release. Login Enter your login name for the service. For FTP and rsync services, this will typically be a user name. For S3 services, it will be an access key ID. For S3 services, you may want to keep your access keys in an environment variable. If you choose to do so, you can enter env: followed by the name of the environment variable here and DART will pull the setting from the environment at run time. For example, if you keep your AWS access key id in an environment variable called AWS_ACCESS_KEY_ID, then enter env:AWS_ACCESS_KEY_ID . Password Enter your password for the service. For FTP and rsync services, this will typically be an actual passowrd. For S3 services, it will be an secret access key. As with the Login field above, you can set this to reference an environment variable using the env: pattern. For example, env:AWS_SECRET_ACCESS_KEY . Login Extra This field is typically not used. If your storage service requires it, the plugin documentation should describe what to enter here. Otherwise, leave this field blank.","title":"Storage Services"},{"location":"users/settings/storage_services/#storage-services","text":"Storage services are not repositories! They are pickup and drop-off points for materials going into or coming out of repositories. Some repositories ask depositors to upload materials into an S3 bucket or an SFTP folder for ingest, and restore materials to a similar bucket or folder for depositors to retrieve. Storage services allow DART to connect to these pickup and drop-off points. Note, however, that you're free to send data to and from these storage services even if they're not ultimately bound for a preservation repository.","title":"Storage Services"},{"location":"users/settings/storage_services/#listing-storage-services","text":"To list all storage services, choose Settings Storage Services from the menu.","title":"Listing Storage Services"},{"location":"users/settings/storage_services/#editing-storage-services","text":"Click any storage servicei in the list to edit it.","title":"Editing Storage Services"},{"location":"users/settings/storage_services/#description-of-settings","text":"","title":"Description of Settings"},{"location":"users/settings/storage_services/#name","text":"The name of the service. Choose a name that's meaningful to you and that differentiates this service from others. You can change the name at any time without affecting the bevavior or availability of the service.","title":"Name"},{"location":"users/settings/storage_services/#description","text":"A description of this service.","title":"Description"},{"location":"users/settings/storage_services/#protocol","text":"Choose the network protocol used to communicate with this service. Note: At launch, DART supports only the S3 protocol.","title":"Protocol"},{"location":"users/settings/storage_services/#host","text":"Enter the name or IP address of the service host. Do not include protocol prefixes like https:// or ftp:// . For example, the host name for Amazon's S3 service is s3.amazonaws.com . A locally hosted service may be s3.example.com or ftp.example.com . You can also enter an IP address here such as 127.0.0.1 .","title":"Host"},{"location":"users/settings/storage_services/#port","text":"The port to connect to. In most cases, you'll want to leave this at 0 (zero). Set this only if the service is running on a non-standard port number.","title":"Port"},{"location":"users/settings/storage_services/#bucket","text":"The name of the bucket you'll be uploading into or downloading from on the remote host. For the S3 protocol, this will be a bucket name like aptrust.dart.test . For protocols like FTP and rsync, this will be a directory name like uploads/ingest/ or downloads/restore .","title":"Bucket"},{"location":"users/settings/storage_services/#allows-upload","text":"Choose Yes if this service allows you to upload files, No otherwise. Info This setting is important. When you run a job, DART gives you a choice of storage services to which to send your files. DART will show only those services where Allows Upload is set to Yes .","title":"Allows Upload"},{"location":"users/settings/storage_services/#allows-download","text":"Choose Yes if this service allows you to download files, No otherwise. Info While DART does not support downloads in its initial release, it may support them in a future release.","title":"Allows Download"},{"location":"users/settings/storage_services/#login","text":"Enter your login name for the service. For FTP and rsync services, this will typically be a user name. For S3 services, it will be an access key ID. For S3 services, you may want to keep your access keys in an environment variable. If you choose to do so, you can enter env: followed by the name of the environment variable here and DART will pull the setting from the environment at run time. For example, if you keep your AWS access key id in an environment variable called AWS_ACCESS_KEY_ID, then enter env:AWS_ACCESS_KEY_ID .","title":"Login"},{"location":"users/settings/storage_services/#password","text":"Enter your password for the service. For FTP and rsync services, this will typically be an actual passowrd. For S3 services, it will be an secret access key. As with the Login field above, you can set this to reference an environment variable using the env: pattern. For example, env:AWS_SECRET_ACCESS_KEY .","title":"Password"},{"location":"users/settings/storage_services/#login-extra","text":"This field is typically not used. If your storage service requires it, the plugin documentation should describe what to enter here. Otherwise, leave this field blank.","title":"Login Extra"},{"location":"users/workflows/","text":"Workflows A workflow is a set of packaging, validation, and/or upload operations that you define as a template to be run on any sets of files you choose. Workflows ensure that the exact same set of steps is run on each set of files. DART can run workflows from the UI and from the command line, which means you can create scripts that use workflows to package and upload materials. Defining a Workflow DART provides two ways to define a workflow: from a job or from scratch. Creating a Workflow from a Job The easiest way to create a workflow is to first create a job that includes all of the operations you want to include, run the job to ensure it works, then click the Convert to Workflow button on the Review and Run screen. Creating a Workflow from Scratch To create a workflow from scratch: Choose Workflows New from the menu. Fill in the details. The Name is required and should describe what the workflow will do. This name will appear on the Workflow menu, and scripted tasks will use this name to reference the workflow. (See #2 under Tips for Workflows below.) The Description is for your internal use. Choose the Package Format that suits your needs. If you chose BagIt as the Package Format, choose which BagIt Profile you want to use to build the bag. (See #1 under Tips for Workflows below.) Choose the destination to which you want to upload the packaged files. Note that only Storage Services where Allows Upload is set to Yes will appear in the Upload To list. Click Save , and remember that you can edit or delete this workflow later. Tips for Workflows Use customized BagIt profiles. DART lets you clone the base version of a BagIt profile and then add your own tag default values, so that you don't have to re-enter those values each time you create a new bag. For example, most BagIt profiles require a value for the Source-Organization tag, and typically, this value will be the same for every bag you create. Most profiles also require a number of other tags that may rarely or never change from bag to bag. For example, most depositors will set the same Access and Storage-Option values for 99% of the bags they upload to APTrust. Including in your workflow a custom BagIt profile with pre-set default values will save you having to re-enter common tag values, while still allowing you to override them when necessary. Use meaningful names for your workflows. Many repositories include both a staging environment and a production environment. You may create workflows that are identical except that one pushes packages into the staging environment while the other pushes to production. DART lets you run workflows directly from the workflow menu. Meaningful names help uses choose the right workflow and understand what the consequences of the actions they are about to take.","title":"Workflows"},{"location":"users/workflows/#workflows","text":"A workflow is a set of packaging, validation, and/or upload operations that you define as a template to be run on any sets of files you choose. Workflows ensure that the exact same set of steps is run on each set of files. DART can run workflows from the UI and from the command line, which means you can create scripts that use workflows to package and upload materials.","title":"Workflows"},{"location":"users/workflows/#defining-a-workflow","text":"DART provides two ways to define a workflow: from a job or from scratch.","title":"Defining a Workflow"},{"location":"users/workflows/#creating-a-workflow-from-a-job","text":"The easiest way to create a workflow is to first create a job that includes all of the operations you want to include, run the job to ensure it works, then click the Convert to Workflow button on the Review and Run screen.","title":"Creating a Workflow from a Job"},{"location":"users/workflows/#creating-a-workflow-from-scratch","text":"To create a workflow from scratch: Choose Workflows New from the menu. Fill in the details. The Name is required and should describe what the workflow will do. This name will appear on the Workflow menu, and scripted tasks will use this name to reference the workflow. (See #2 under Tips for Workflows below.) The Description is for your internal use. Choose the Package Format that suits your needs. If you chose BagIt as the Package Format, choose which BagIt Profile you want to use to build the bag. (See #1 under Tips for Workflows below.) Choose the destination to which you want to upload the packaged files. Note that only Storage Services where Allows Upload is set to Yes will appear in the Upload To list. Click Save , and remember that you can edit or delete this workflow later.","title":"Creating a Workflow from Scratch"},{"location":"users/workflows/#tips-for-workflows","text":"Use customized BagIt profiles. DART lets you clone the base version of a BagIt profile and then add your own tag default values, so that you don't have to re-enter those values each time you create a new bag. For example, most BagIt profiles require a value for the Source-Organization tag, and typically, this value will be the same for every bag you create. Most profiles also require a number of other tags that may rarely or never change from bag to bag. For example, most depositors will set the same Access and Storage-Option values for 99% of the bags they upload to APTrust. Including in your workflow a custom BagIt profile with pre-set default values will save you having to re-enter common tag values, while still allowing you to override them when necessary. Use meaningful names for your workflows. Many repositories include both a staging environment and a production environment. You may create workflows that are identical except that one pushes packages into the staging environment while the other pushes to production. DART lets you run workflows directly from the workflow menu. Meaningful names help uses choose the right workflow and understand what the consequences of the actions they are about to take.","title":"Tips for Workflows"},{"location":"users/workflows/job_params/","text":"Job Params The JobParams object is a simple JSON structure that gives a DART command-line job four essential pieces of information it needs to run a job. These are: workflowName - The name of the workflow to run. packageName - The name of the package to create. files - A list of files and/or directories to put into the package and/or upload to a remote server. If the workflow incudes one or more upload operations but no packaging operation, the files will be uploaded directly. tags - A list of tag names and values to add to the package. Below is sample JobParams JSON describing which files should be passed through the \"APTrust Demo System Workflow\" and what tag values should be applied. In this case, two directories and one file will be packaged with four custom-defined tags. { workflowName : APTrust Demo System Workflow , packageName : test.edu.my_files.tar , files : [ /path/to/first/directory , /path/to/second/directory , /path/to/some/document.pdf ], tags : [ { tagFile : bag-info.txt , tagName : Bag-Group-Identifier , userValue : Photos_2019 }, { tagFile : aptrust-info.txt , tagName : Title , userValue : Photos from 2019 }, { tagFile : aptrust-info.txt , tagName : Description , userValue : What I did with my summer vacation. }, { tagFile : custom/legal-info.txt , tagName : License , userValue : https://creativecommons.org/publicdomain/zero/1.0/ } ] } Let's assume the hypothetical \"APTrust Demo System Workflow\" includes the following steps: Package all files according to our customized version of the APTrust BagIt profile. Validate the resulting bag. Upload the bag to our ingest bucket for the APTrust Demo system. Upload the bag to the S3 bucket in our local owncloud S3 service. Passing the JSON above to the DART command line application will result in the following: The file /path/to/some/document.pdf and the contents of the directories /path/to/first/directory and /path/to/second/directory will be packed into the data directory of a new BagIt bag. DART will create and populate all of the tag files required by the APTrust BagIt profile. It will use the default values saved in your locally customized version of the profile where possible, overriding the defaults with the bag-specific values supplied in the JSON. Note Note that certain BagIt tag values, such as Source-Organization, Contact-Email, etc. will not change from bag to bag, so it makes sense to set default values for them in your customized profile. Other values, such as bag title and description, will change for every bag, so it makes sense to set them in the JobParams JSON. DART will save the entire package to a file whose name matches the package name. DART will write the file into your bagging directory, which is usually a directory called .dart under your home directory. You can verify (and change) the name of your bagging directory by choosing App Settings from the DART menu and clicking on the setting called Bagging Directory . DART will verify the bag according to the APTrust BagIt profile (or whichever profile the Workflow specified). DART will upload the verified bag to APTrust's S3 ingest bucket. DART will upload the verified bag to your local ownCloud S3 bucket. See also: Workflows , Command Line Reference , Scripting with DART Further Reading You'll find more detailed developer documentation for the JobParams object in our DART API documentation .","title":"Job Params"},{"location":"users/workflows/job_params/#job-params","text":"The JobParams object is a simple JSON structure that gives a DART command-line job four essential pieces of information it needs to run a job. These are: workflowName - The name of the workflow to run. packageName - The name of the package to create. files - A list of files and/or directories to put into the package and/or upload to a remote server. If the workflow incudes one or more upload operations but no packaging operation, the files will be uploaded directly. tags - A list of tag names and values to add to the package. Below is sample JobParams JSON describing which files should be passed through the \"APTrust Demo System Workflow\" and what tag values should be applied. In this case, two directories and one file will be packaged with four custom-defined tags. { workflowName : APTrust Demo System Workflow , packageName : test.edu.my_files.tar , files : [ /path/to/first/directory , /path/to/second/directory , /path/to/some/document.pdf ], tags : [ { tagFile : bag-info.txt , tagName : Bag-Group-Identifier , userValue : Photos_2019 }, { tagFile : aptrust-info.txt , tagName : Title , userValue : Photos from 2019 }, { tagFile : aptrust-info.txt , tagName : Description , userValue : What I did with my summer vacation. }, { tagFile : custom/legal-info.txt , tagName : License , userValue : https://creativecommons.org/publicdomain/zero/1.0/ } ] } Let's assume the hypothetical \"APTrust Demo System Workflow\" includes the following steps: Package all files according to our customized version of the APTrust BagIt profile. Validate the resulting bag. Upload the bag to our ingest bucket for the APTrust Demo system. Upload the bag to the S3 bucket in our local owncloud S3 service. Passing the JSON above to the DART command line application will result in the following: The file /path/to/some/document.pdf and the contents of the directories /path/to/first/directory and /path/to/second/directory will be packed into the data directory of a new BagIt bag. DART will create and populate all of the tag files required by the APTrust BagIt profile. It will use the default values saved in your locally customized version of the profile where possible, overriding the defaults with the bag-specific values supplied in the JSON. Note Note that certain BagIt tag values, such as Source-Organization, Contact-Email, etc. will not change from bag to bag, so it makes sense to set default values for them in your customized profile. Other values, such as bag title and description, will change for every bag, so it makes sense to set them in the JobParams JSON. DART will save the entire package to a file whose name matches the package name. DART will write the file into your bagging directory, which is usually a directory called .dart under your home directory. You can verify (and change) the name of your bagging directory by choosing App Settings from the DART menu and clicking on the setting called Bagging Directory . DART will verify the bag according to the APTrust BagIt profile (or whichever profile the Workflow specified). DART will upload the verified bag to APTrust's S3 ingest bucket. DART will upload the verified bag to your local ownCloud S3 bucket. See also: Workflows , Command Line Reference , Scripting with DART","title":"Job Params"},{"location":"users/workflows/job_params/#further-reading","text":"You'll find more detailed developer documentation for the JobParams object in our DART API documentation .","title":"Further Reading"}]}