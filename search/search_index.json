{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to DART DART is the Digital Archivist's Resource Tool. It provides both a GUI and a command-line interface for packaging files and uploading them to remote repositories. Supported Operations The initial release of DART 2.0 supports the following features: Creating BagIt bags that conform to defined BagIt profiles Validating BagIt bags according to defined BagIt profiles Uploading bags and other files to remote S3 endpoints Creating and modifying BagIt profiles through a visual point-and-click editor Defining repeatable Workflows for bagging and uploading files Running multiple simultaneous bagging and upload jobs Read-only integration with the APTrust's REST API to display the status of ingested materials and pending work items A command-line tool to enable scriptable bagging and upload operations To start using DART, see our Getting Started page. Plugin Architecture Most of DART's features are implemented in plugins, which enable developers to add new features without having to understand all of DART's internals. DART is an open source project of the Academic Preservation Trust, which encourages developers to contribute new plugins to extend the tool's functionality. DART 2.0 supports the following types of plugins: Format Readers - These allow DART to read files packaged in various formats, such as tar, zip, rar, parchive, OCFL, etc. Currently supported in formats in version 2.0: directory/file system tar Format Writers - These allow DART to write files in various formats, such as tar, zip, rar, parchive, OCFL, etc. Currently supported in formats in version 2.0: directory/file system tar Network Clients - These allow DART to send and retrieve files across a network. DART 2.0 supports the following protocols: S3 Repository Clients - These allow DART to interact with remote repositories. Currently supported: APTrust Setup Modules - These allow organizations to install default settings and create a list of simple questions to get local users up and running quickly. Currently supported: APTrust DPN Writing DART plugins requires a working knowledge of JavaScript and HTML. If you're interested in developing DART plugins, see our Developers page and our full API documentation . Useful Links Getting Started with DART Developing DART Plugins DART API documentation DART source code on GitHub Credits Brace yourselves gentlemen. According to the gas chromatograph, the secret ingredient is... Love!? Who's been screwing with this thing?","title":"Home"},{"location":"#welcome-to-dart","text":"DART is the Digital Archivist's Resource Tool. It provides both a GUI and a command-line interface for packaging files and uploading them to remote repositories.","title":"Welcome to DART"},{"location":"#supported-operations","text":"The initial release of DART 2.0 supports the following features: Creating BagIt bags that conform to defined BagIt profiles Validating BagIt bags according to defined BagIt profiles Uploading bags and other files to remote S3 endpoints Creating and modifying BagIt profiles through a visual point-and-click editor Defining repeatable Workflows for bagging and uploading files Running multiple simultaneous bagging and upload jobs Read-only integration with the APTrust's REST API to display the status of ingested materials and pending work items A command-line tool to enable scriptable bagging and upload operations To start using DART, see our Getting Started page.","title":"Supported Operations"},{"location":"#plugin-architecture","text":"Most of DART's features are implemented in plugins, which enable developers to add new features without having to understand all of DART's internals. DART is an open source project of the Academic Preservation Trust, which encourages developers to contribute new plugins to extend the tool's functionality. DART 2.0 supports the following types of plugins: Format Readers - These allow DART to read files packaged in various formats, such as tar, zip, rar, parchive, OCFL, etc. Currently supported in formats in version 2.0: directory/file system tar Format Writers - These allow DART to write files in various formats, such as tar, zip, rar, parchive, OCFL, etc. Currently supported in formats in version 2.0: directory/file system tar Network Clients - These allow DART to send and retrieve files across a network. DART 2.0 supports the following protocols: S3 Repository Clients - These allow DART to interact with remote repositories. Currently supported: APTrust Setup Modules - These allow organizations to install default settings and create a list of simple questions to get local users up and running quickly. Currently supported: APTrust DPN Writing DART plugins requires a working knowledge of JavaScript and HTML. If you're interested in developing DART plugins, see our Developers page and our full API documentation .","title":"Plugin Architecture"},{"location":"#useful-links","text":"Getting Started with DART Developing DART Plugins DART API documentation DART source code on GitHub","title":"Useful Links"},{"location":"#credits","text":"Brace yourselves gentlemen. According to the gas chromatograph, the secret ingredient is... Love!? Who's been screwing with this thing?","title":"Credits"},{"location":"developers/","text":"Developer's Guide to DART Design Principles Yadda yadda yadda. Section One Write you some code. Section Two Test your code. Section Three Document your code.","title":"Developer's Guide to DART"},{"location":"developers/#developers-guide-to-dart","text":"","title":"Developer's Guide to DART"},{"location":"developers/#design-principles","text":"Yadda yadda yadda.","title":"Design Principles"},{"location":"developers/#section-one","text":"Write you some code.","title":"Section One"},{"location":"developers/#section-two","text":"Test your code.","title":"Section Two"},{"location":"developers/#section-three","text":"Document your code.","title":"Section Three"},{"location":"developers/architecture/","text":"Architecture Tech Stack Electron, Node.js, HTML 5, Bootstrap, Handlebars Design choices: limit dynamnic JS, lightweight page loads MVC Pattern Similar to Rails. Dead simple. Fast, lightweight page reloads. Reduces JS complexity. Handlebars templates are brain dead.","title":"Architecture"},{"location":"developers/architecture/#architecture","text":"","title":"Architecture"},{"location":"developers/architecture/#tech-stack","text":"Electron, Node.js, HTML 5, Bootstrap, Handlebars Design choices: limit dynamnic JS, lightweight page loads","title":"Tech Stack"},{"location":"developers/architecture/#mvc-pattern","text":"Similar to Rails. Dead simple. Fast, lightweight page reloads. Reduces JS complexity. Handlebars templates are brain dead.","title":"MVC Pattern"},{"location":"developers/building/","text":"Building Building DART","title":"Building"},{"location":"developers/building/#building","text":"Building DART","title":"Building"},{"location":"developers/data_storage/","text":"Data Storage JSON only, plain text. Describe location of data files, PersistentObject.","title":"Data Storage"},{"location":"developers/data_storage/#data-storage","text":"JSON only, plain text. Describe location of data files, PersistentObject.","title":"Data Storage"},{"location":"developers/documenting/","text":"Documenting DART Document your code. Someone will have to maintain it!","title":"Documenting"},{"location":"developers/documenting/#documenting-dart","text":"Document your code. Someone will have to maintain it!","title":"Documenting DART"},{"location":"developers/job_flow/","text":"Job Flow Describe workers. What happens when you run a job?","title":"Job Flow"},{"location":"developers/job_flow/#job-flow","text":"Describe workers. What happens when you run a job?","title":"Job Flow"},{"location":"developers/logging/","text":"Logging Where the logs are written. Tailing the logs to see what's happening. Using the logger in your own code.","title":"Logging"},{"location":"developers/logging/#logging","text":"Where the logs are written. Tailing the logs to see what's happening. Using the logger in your own code.","title":"Logging"},{"location":"developers/testing/","text":"Testing DART Running existing tests. Writing tests for your modules.","title":"Testing"},{"location":"developers/testing/#testing-dart","text":"Running existing tests. Writing tests for your modules.","title":"Testing DART"},{"location":"developers/plugins/","text":"Plugins About... Describe the anatomy of a plugin description.","title":"Plugins"},{"location":"developers/plugins/#plugins","text":"About... Describe the anatomy of a plugin description.","title":"Plugins"},{"location":"developers/plugins/format_readers/","text":"Format Readers What they do. How to write one.","title":"Format Readers"},{"location":"developers/plugins/format_readers/#format-readers","text":"What they do. How to write one.","title":"Format Readers"},{"location":"developers/plugins/format_writers/","text":"Format Writers What they do. How to write one.","title":"Format Writers"},{"location":"developers/plugins/format_writers/#format-writers","text":"What they do. How to write one.","title":"Format Writers"},{"location":"developers/plugins/manager/","text":"Plugin Manager About the plugin manager.","title":"Plugin Manager"},{"location":"developers/plugins/manager/#plugin-manager","text":"About the plugin manager.","title":"Plugin Manager"},{"location":"developers/plugins/network_clients/","text":"Network Clients What they do. How they enable new types of storage services. How they show up in the providers list. How to write one.","title":"Network Clients"},{"location":"developers/plugins/network_clients/#network-clients","text":"What they do. How they enable new types of storage services. How they show up in the providers list. How to write one.","title":"Network Clients"},{"location":"developers/plugins/repo_clients/","text":"Repository Clients What they do. Requirements: REST API. Inputs and outputs.","title":"Repository Clients"},{"location":"developers/plugins/repo_clients/#repository-clients","text":"What they do. Requirements: REST API. Inputs and outputs.","title":"Repository Clients"},{"location":"developers/plugins/setup_modules/","text":"Setup Modules Describe what they do and why they're useful. Describe how to build and test them.","title":"Setup Modules"},{"location":"developers/plugins/setup_modules/#setup-modules","text":"Describe what they do and why they're useful. Describe how to build and test them.","title":"Setup Modules"},{"location":"users/command_line/","text":"Command Line Reference DART provides several ways of running jobs from the command line. The most convenient method, and the easiest to script, is to define a workflow and then create a JobParams object that describes which files to pass through the workflow and what custom metadata attributes to assign. Note that in all of these examples, the dart command is followed by two dashes, and then the command-line parameters. Parameters to the left of the double dash will be consumed by the Node.js runtime, while those to the right will be passed to DART. From a JobParams JSON file dart -- --job path/to/job_params.json From JobParams JSON passed through STDIN echo \"{ ... json ... } | dart -- --stdin\" From a Job JSON file dart -- --job path/to/job.json Note: DART does not yet export jobs to JSON. That feature is in the works. From Job JSON passed through STDIN echo { ... json ... } | dart -- --stdin Note Job JSON can be relatively large, since it may include a BagIt profile. Using JobParams is generally easier than using Jobs. By Job UUID dart -- --job 00000000-0000-0000-0000-000000000000 Note The ability to extract Job UUIDs from DART is coming soon. As of this writing (July 22, 2019), some elements of the CLI are subject to change and further development. Resource Usage and Known Issues DART uses Node.js, which is a relatively fast, efficient JavaScript runtime. Node, however, can use large amounts of memory, often 10-30 times what a similar application written in Go or C++ may use. You can expect each DART command-line process to use at least 50 MB of RAM on startup, and sometimes over 150 MB at runtime if it when creating large packages. Potentially High Memory Usage During S3 Uploads DART consumes the most memory when uploading large files to an S3-compliant endpoint. S3 clients need to load chunks of data into memory before streaming them across the network. When uploading a file of 100 MB, each chunk may be only 5-50 MB in size, increasing DART's memory usage by that amound until the chunk has been copied to the remote server. S3 allows uploads of up to 5 TB, with a maximum of 10,000 chunks. This means that when uploading a 5 TB file, DART's underlying S3 client will load chunks of about 535 MB each into memory. That's a considerable amount of memory, particularly on a computer that likely has a number of other open appilcations. For this reason, it's best to avoid running multiple simultaneous multi-terabyte jobs. Disk Usage When Creating Large Packages When you're packaging very large files, keep in mind that you may run out of disk space. For example, DART needs about 5 TB of disk space to create a 5 TB bag. DART is fairly efficient about this, writing contents directly into a tar archive when possible to avoid multiple copies, and calculating all checksums in a single pass during the writes. However, if you're creating a 5 TB bag and you don't have 5 TB of disk space, the job is going to fail. Note that you can change the location of your bagging directory by choosing Settings App Settings from the menu and then clicking Bagging Directory . You can also change your bagging directory for a single job by setting the Output Path for that job. If you need extra disk space for a particular job, consider using a network share or an external USB drive as your bagging directory. Checking the Logs for Failed Jobs DART logs all of its work. If a job fails, check the logs for details. Sharing Jobs Note that because details of jobs, workflows, and storage services are stored on your local DART computer, workflows and JobParams defined on one machine will not run on another machine that does not have matching settings.","title":"Command Line Reference"},{"location":"users/command_line/#command-line-reference","text":"DART provides several ways of running jobs from the command line. The most convenient method, and the easiest to script, is to define a workflow and then create a JobParams object that describes which files to pass through the workflow and what custom metadata attributes to assign. Note that in all of these examples, the dart command is followed by two dashes, and then the command-line parameters. Parameters to the left of the double dash will be consumed by the Node.js runtime, while those to the right will be passed to DART. From a JobParams JSON file dart -- --job path/to/job_params.json From JobParams JSON passed through STDIN echo \"{ ... json ... } | dart -- --stdin\" From a Job JSON file dart -- --job path/to/job.json Note: DART does not yet export jobs to JSON. That feature is in the works. From Job JSON passed through STDIN echo { ... json ... } | dart -- --stdin Note Job JSON can be relatively large, since it may include a BagIt profile. Using JobParams is generally easier than using Jobs. By Job UUID dart -- --job 00000000-0000-0000-0000-000000000000 Note The ability to extract Job UUIDs from DART is coming soon. As of this writing (July 22, 2019), some elements of the CLI are subject to change and further development.","title":"Command Line Reference"},{"location":"users/command_line/#resource-usage-and-known-issues","text":"DART uses Node.js, which is a relatively fast, efficient JavaScript runtime. Node, however, can use large amounts of memory, often 10-30 times what a similar application written in Go or C++ may use. You can expect each DART command-line process to use at least 50 MB of RAM on startup, and sometimes over 150 MB at runtime if it when creating large packages.","title":"Resource Usage and Known Issues"},{"location":"users/command_line/#potentially-high-memory-usage-during-s3-uploads","text":"DART consumes the most memory when uploading large files to an S3-compliant endpoint. S3 clients need to load chunks of data into memory before streaming them across the network. When uploading a file of 100 MB, each chunk may be only 5-50 MB in size, increasing DART's memory usage by that amound until the chunk has been copied to the remote server. S3 allows uploads of up to 5 TB, with a maximum of 10,000 chunks. This means that when uploading a 5 TB file, DART's underlying S3 client will load chunks of about 535 MB each into memory. That's a considerable amount of memory, particularly on a computer that likely has a number of other open appilcations. For this reason, it's best to avoid running multiple simultaneous multi-terabyte jobs.","title":"Potentially High Memory Usage During S3 Uploads"},{"location":"users/command_line/#disk-usage-when-creating-large-packages","text":"When you're packaging very large files, keep in mind that you may run out of disk space. For example, DART needs about 5 TB of disk space to create a 5 TB bag. DART is fairly efficient about this, writing contents directly into a tar archive when possible to avoid multiple copies, and calculating all checksums in a single pass during the writes. However, if you're creating a 5 TB bag and you don't have 5 TB of disk space, the job is going to fail. Note that you can change the location of your bagging directory by choosing Settings App Settings from the menu and then clicking Bagging Directory . You can also change your bagging directory for a single job by setting the Output Path for that job. If you need extra disk space for a particular job, consider using a network share or an external USB drive as your bagging directory.","title":"Disk Usage When Creating Large Packages"},{"location":"users/command_line/#checking-the-logs-for-failed-jobs","text":"DART logs all of its work. If a job fails, check the logs for details.","title":"Checking the Logs for Failed Jobs"},{"location":"users/command_line/#sharing-jobs","text":"Note that because details of jobs, workflows, and storage services are stored on your local DART computer, workflows and JobParams defined on one machine will not run on another machine that does not have matching settings.","title":"Sharing Jobs"},{"location":"users/dashboard/","text":"Dashboard The dashboard shows running jobs, recently completed jobs, and selected items from remote repositories. Running Jobs The Running Jobs panel shows jobs DART is currently running on your computer. If more than one job is currently running, you can scroll inside the panel to see the progress of each. Also note the blue badge in the upper right corner of the window showing there are two running jobs. The blue badge appears on all DART views as long as jobs are running. Note that DART runs each job in a separate process. Actions you take in DART do not affect the running jobs. Warning When you shut down the DART application, all DART jobs stop, even if they are not yet complete. Don't close the DART window while jobs are running, unless you intend to stop all of the jobs. Progress Bars for Running Jobs The progress bars for running jobs show how much progress DART has made in each of the job's steps, which may include packaging, validation, and/or uploading. Info While the progress bars for packaging and validation are very accurate, the progress bar for uploads runs slightly ahead of the actual upload progress. DART knows how many bytes of an upload it has prepared to send, but not how many have been received by the remote host. It's common for the upload progress bar to appear to stall at about 98% while the last chunk of data goes across the wire. For smaller uploads, the stall may last only a second or two. For very large uploads, the final chunk may be hundreds of megabytes and may take several minutes to complete. Recent Jobs The Recent Jobs panel lists recently completed jobs. The Outcome column shows the job's last completed step, while the Date column shows when that step was completed. You can get more detailed information by clicking Jobs List from the top menu. See also: Jobs Repositories The Repositories panels show items from remote repositories that DART knows how to connect to. In the screenshot above, this panel shows items recently ingested into APTrust's demo repository: The panel below shows a list of pending or recently completed tasks from APTrust demo system. Some repository panels, such as those from APTrust, show additional information when you mouse over an item. The panels show errors if they cannot communicate with the remote repository. If you run into errors like this, chances are your Remote Repository is incorrectly configured. Info Remote repository panels require both a correctly configured Remote Repository setting and a plugin that knows how to communicate with the remote repository. Plugins are typically written by developers associated with the repository, and are packaged with the DART installation. See also: Remote Repository","title":"Dashboard"},{"location":"users/dashboard/#dashboard","text":"The dashboard shows running jobs, recently completed jobs, and selected items from remote repositories.","title":"Dashboard"},{"location":"users/dashboard/#running-jobs","text":"The Running Jobs panel shows jobs DART is currently running on your computer. If more than one job is currently running, you can scroll inside the panel to see the progress of each. Also note the blue badge in the upper right corner of the window showing there are two running jobs. The blue badge appears on all DART views as long as jobs are running. Note that DART runs each job in a separate process. Actions you take in DART do not affect the running jobs. Warning When you shut down the DART application, all DART jobs stop, even if they are not yet complete. Don't close the DART window while jobs are running, unless you intend to stop all of the jobs.","title":"Running Jobs"},{"location":"users/dashboard/#progress-bars-for-running-jobs","text":"The progress bars for running jobs show how much progress DART has made in each of the job's steps, which may include packaging, validation, and/or uploading. Info While the progress bars for packaging and validation are very accurate, the progress bar for uploads runs slightly ahead of the actual upload progress. DART knows how many bytes of an upload it has prepared to send, but not how many have been received by the remote host. It's common for the upload progress bar to appear to stall at about 98% while the last chunk of data goes across the wire. For smaller uploads, the stall may last only a second or two. For very large uploads, the final chunk may be hundreds of megabytes and may take several minutes to complete.","title":"Progress Bars for Running Jobs"},{"location":"users/dashboard/#recent-jobs","text":"The Recent Jobs panel lists recently completed jobs. The Outcome column shows the job's last completed step, while the Date column shows when that step was completed. You can get more detailed information by clicking Jobs List from the top menu. See also: Jobs","title":"Recent Jobs"},{"location":"users/dashboard/#repositories","text":"The Repositories panels show items from remote repositories that DART knows how to connect to. In the screenshot above, this panel shows items recently ingested into APTrust's demo repository: The panel below shows a list of pending or recently completed tasks from APTrust demo system. Some repository panels, such as those from APTrust, show additional information when you mouse over an item. The panels show errors if they cannot communicate with the remote repository. If you run into errors like this, chances are your Remote Repository is incorrectly configured. Info Remote repository panels require both a correctly configured Remote Repository setting and a plugin that knows how to communicate with the remote repository. Plugins are typically written by developers associated with the repository, and are packaged with the DART installation. See also: Remote Repository","title":"Repositories"},{"location":"users/getting_started/","text":"Getting Started DART is the Digital Archivist's Resource Tool. Its primary purpose is to package digital materials and send them off to long-term preservation storage. DART's initial release focuses on packaging materials in BagIt format and uploading them to S3 buckets for ingest in APTrust. DART can be extended through plugins to produce other packaging formats and to communicated via additional network protocols. DART runs in both graphical and command-line modes on Windows, Mac, and Linux. Installation Download the DART installer for your system. Mac : https://s3.amazonaws.com/aptrust.public.download/DART/DART-2.0.0.dmg Windows : https://s3.amazonaws.com/aptrust.public.download/DART/DART+Setup+2.0.0.exe Linux : https://s3.amazonaws.com/aptrust.public.download/DART/DART_2.0.0_amd64.deb Double-click the installer after download and follow the prompts on screen. Set Up After installation, DART includes two BagIt profiles by default, one for APTrust and one for DPN. You can use one of these two profiles to create your first job. While jobs can include packaging, validation, and upload operations, you won't be able to upload anything until you've set up a Storage Service to receive an upload. With this, your first job will be limited to creating and validating a BagIt bag. Running Your First Job Follow these steps to create a valid local bag that conforms to the APTrust BagIt profile: Choose Jobs New from the main menu. Drag some files or folders into the files window. To avoid a long-running job that will consume a lot of disk space, choose only a few megabytes of files. Click Next and set the following: Packaging Format : BagIt BagIt Profile : APTrust Package Name : test_bag Output Path : Don't edit this for now. DART will set it for you. Click Next and set the required metadata attributes, which are marked with a red asterisk. For an APTrust bag, these include the Access and Title tags in the aptrust-info.txt file, and the Source-Organization tag in the bag-info.txt file. Click Next to choose the upload targets. Since there will be no available upload targets after initial installtion, Click Next again. The Review and Run screen shows the details of the job you've just defined. Click Run Job to run the job. When the job is complete, you'll find your bag in the Output Path displayed on the Review and Run screen. Further Reading BagIt Profiles describes how to build an customize BagIt profiles, so DART can build bags exactly as you want them. Be sure to read the section on tag default values under Editing a Tag . That will save you from re-entering common tag values, such as Source-Organization, every time you create a new bag. The Dashboard displays information about currently running and recently completed jobs. If you've configured Remote Repository connections, the dashboard can show the status of recent and pending ingests. To get details about what DART is doing, check the Logs . The Settings section describes how to set up upload targets, remote repository connections, and more. Organizations that distribute DART to their members can create Setup Modules to automatically configure DART for their needs. After you've defined and tested a successful job, you can convert it to a Workflow to run other files through the same process.","title":"Getting Started"},{"location":"users/getting_started/#getting-started","text":"DART is the Digital Archivist's Resource Tool. Its primary purpose is to package digital materials and send them off to long-term preservation storage. DART's initial release focuses on packaging materials in BagIt format and uploading them to S3 buckets for ingest in APTrust. DART can be extended through plugins to produce other packaging formats and to communicated via additional network protocols. DART runs in both graphical and command-line modes on Windows, Mac, and Linux.","title":"Getting Started"},{"location":"users/getting_started/#installation","text":"Download the DART installer for your system. Mac : https://s3.amazonaws.com/aptrust.public.download/DART/DART-2.0.0.dmg Windows : https://s3.amazonaws.com/aptrust.public.download/DART/DART+Setup+2.0.0.exe Linux : https://s3.amazonaws.com/aptrust.public.download/DART/DART_2.0.0_amd64.deb Double-click the installer after download and follow the prompts on screen.","title":"Installation"},{"location":"users/getting_started/#set-up","text":"After installation, DART includes two BagIt profiles by default, one for APTrust and one for DPN. You can use one of these two profiles to create your first job. While jobs can include packaging, validation, and upload operations, you won't be able to upload anything until you've set up a Storage Service to receive an upload. With this, your first job will be limited to creating and validating a BagIt bag.","title":"Set Up"},{"location":"users/getting_started/#running-your-first-job","text":"Follow these steps to create a valid local bag that conforms to the APTrust BagIt profile: Choose Jobs New from the main menu. Drag some files or folders into the files window. To avoid a long-running job that will consume a lot of disk space, choose only a few megabytes of files. Click Next and set the following: Packaging Format : BagIt BagIt Profile : APTrust Package Name : test_bag Output Path : Don't edit this for now. DART will set it for you. Click Next and set the required metadata attributes, which are marked with a red asterisk. For an APTrust bag, these include the Access and Title tags in the aptrust-info.txt file, and the Source-Organization tag in the bag-info.txt file. Click Next to choose the upload targets. Since there will be no available upload targets after initial installtion, Click Next again. The Review and Run screen shows the details of the job you've just defined. Click Run Job to run the job. When the job is complete, you'll find your bag in the Output Path displayed on the Review and Run screen.","title":"Running Your First Job"},{"location":"users/getting_started/#further-reading","text":"BagIt Profiles describes how to build an customize BagIt profiles, so DART can build bags exactly as you want them. Be sure to read the section on tag default values under Editing a Tag . That will save you from re-entering common tag values, such as Source-Organization, every time you create a new bag. The Dashboard displays information about currently running and recently completed jobs. If you've configured Remote Repository connections, the dashboard can show the status of recent and pending ingests. To get details about what DART is doing, check the Logs . The Settings section describes how to set up upload targets, remote repository connections, and more. Organizations that distribute DART to their members can create Setup Modules to automatically configure DART for their needs. After you've defined and tested a successful job, you can convert it to a Workflow to run other files through the same process.","title":"Further Reading"},{"location":"users/logs/","text":"Logs DART logs most of its activities as it works. If you're looking for detailed infomation about what DART is doing or has done, or if you want to see detailed error messages, check the logs. The easiest way to view the DART log is to click Help Logs from the menu. This will display a live log window that shows updates as they are written. The About dialog will show the location of the DART log file.","title":"Logs"},{"location":"users/logs/#logs","text":"DART logs most of its activities as it works. If you're looking for detailed infomation about what DART is doing or has done, or if you want to see detailed error messages, check the logs. The easiest way to view the DART log is to click Help Logs from the menu. This will display a live log window that shows updates as they are written. The About dialog will show the location of the DART log file.","title":"Logs"},{"location":"users/scripting/","text":"Scripting with DART The easiest way to script DART jobs is to: Create a workflow . Info If your workflow includes generating bags, you should also create a custom BagIt profile with default values so that your script will only need to create a few bag-specific tag values at runtime. See Customizing BagIt Profiles for more info. Create a simple data object that can be transformed into a JSON structure that matches DART's JobParams object. Pass the JSON to the DART command through STDIN. The examples below show how to do this in Ruby and Python. Note that both examples create the following JSON structure. { workflowName : DART Test Workflow , packageName : test.edu.my_files.tar , files : [ /Users/apd4n/aptrust/dart-docs/site , /Users/apd4n/tmp/logs ], tags : [{ tagFile : bag-info.txt , tagName : Bag-Group-Identifier , userValue : TestGroup_001 }, { tagFile : aptrust-info.txt , tagName : Title , userValue : Workflow Test Files }, { tagFile : aptrust-info.txt , tagName : Description , userValue : Contains miscellaneous files for workflow testing. }] } Example: Ruby To script DART actions, you'll need one simple Ruby class that allows you to define and run a job. You can cut and paste this to get started, but note that you will likely have to change the value of @@dart_command to point to the DART executable on your local machine. require json class Job # Be sure to set this appropriately for your system. # The command npm start is for DART development use only. @@dart_command = npm start attr_accessor :workflow_name , :package_name , :files , :tags def initialize ( workflow_name , package_name ) @workflow_name = workflow_name @package_name = package_name @files = [] @tags = [] end def to_json ( options = {}) { workflowName : workflow_name , packageName : package_name , files : files , tags : tags } . to_json end def add_file ( path ) @files path end def add_tag ( tag_file , tag_name , value ) @tags { tagFile : tag_file , tagName : tag_name , userValue : value } end def run json_string = self . to_json puts json_string puts Starting job opts = { external_encoding : UTF-8 , err : [ :child , :out ] } IO . popen ( #{ @@dart_command } -- --stdin , r+ , opts ) { | pipe | pipe . write json_string + \\n pipe . close_write puts pipe . read } return $? . exitstatus end end Assuming you saved the code above to a file called job.rb , you can create a script like the following to run a job based on a pre-defined DART workflow. require ./job # Create a new job using the DART Test Workflow. # This job will create a tarred bag called test.edu.my_files.tar # in your DART bagging directory. job = Job . new ( DART Test Workflow , test.edu.my_files.tar ) # Add two directories to the list of items that should go into # the bag s payload. Note that you can add a mix of files and # directories. job . add_file ( /Users/apd4n/aptrust/dart-docs/site ) job . add_file ( /Users/apd4n/tmp/logs ) # DART Test Workflow uses a BagIt profile with a number of # preset default values, which are fine for tags like Contact-Email, # which doesn t change from bag to bag. Here we set bag-specific # tag values. job . add_tag ( bag-info.txt , Bag-Group-Identifier , TestGroup_001 ) job . add_tag ( aptrust-info.txt , Title , Workflow Test Files ) job . add_tag ( aptrust-info.txt , Description , Contains miscellaneous files for workflow testing. ) # Run the job and check the exit code. 0 indicates success. # Non-zero values indicate failure. exit_code = job . run () if exit_code == 0 puts Job completed else puts Job failed. Check the DART log for details. end Example: Python Coming soon...","title":"Scripting with DART"},{"location":"users/scripting/#scripting-with-dart","text":"The easiest way to script DART jobs is to: Create a workflow . Info If your workflow includes generating bags, you should also create a custom BagIt profile with default values so that your script will only need to create a few bag-specific tag values at runtime. See Customizing BagIt Profiles for more info. Create a simple data object that can be transformed into a JSON structure that matches DART's JobParams object. Pass the JSON to the DART command through STDIN. The examples below show how to do this in Ruby and Python. Note that both examples create the following JSON structure. { workflowName : DART Test Workflow , packageName : test.edu.my_files.tar , files : [ /Users/apd4n/aptrust/dart-docs/site , /Users/apd4n/tmp/logs ], tags : [{ tagFile : bag-info.txt , tagName : Bag-Group-Identifier , userValue : TestGroup_001 }, { tagFile : aptrust-info.txt , tagName : Title , userValue : Workflow Test Files }, { tagFile : aptrust-info.txt , tagName : Description , userValue : Contains miscellaneous files for workflow testing. }] }","title":"Scripting with DART"},{"location":"users/scripting/#example-ruby","text":"To script DART actions, you'll need one simple Ruby class that allows you to define and run a job. You can cut and paste this to get started, but note that you will likely have to change the value of @@dart_command to point to the DART executable on your local machine. require json class Job # Be sure to set this appropriately for your system. # The command npm start is for DART development use only. @@dart_command = npm start attr_accessor :workflow_name , :package_name , :files , :tags def initialize ( workflow_name , package_name ) @workflow_name = workflow_name @package_name = package_name @files = [] @tags = [] end def to_json ( options = {}) { workflowName : workflow_name , packageName : package_name , files : files , tags : tags } . to_json end def add_file ( path ) @files path end def add_tag ( tag_file , tag_name , value ) @tags { tagFile : tag_file , tagName : tag_name , userValue : value } end def run json_string = self . to_json puts json_string puts Starting job opts = { external_encoding : UTF-8 , err : [ :child , :out ] } IO . popen ( #{ @@dart_command } -- --stdin , r+ , opts ) { | pipe | pipe . write json_string + \\n pipe . close_write puts pipe . read } return $? . exitstatus end end Assuming you saved the code above to a file called job.rb , you can create a script like the following to run a job based on a pre-defined DART workflow. require ./job # Create a new job using the DART Test Workflow. # This job will create a tarred bag called test.edu.my_files.tar # in your DART bagging directory. job = Job . new ( DART Test Workflow , test.edu.my_files.tar ) # Add two directories to the list of items that should go into # the bag s payload. Note that you can add a mix of files and # directories. job . add_file ( /Users/apd4n/aptrust/dart-docs/site ) job . add_file ( /Users/apd4n/tmp/logs ) # DART Test Workflow uses a BagIt profile with a number of # preset default values, which are fine for tags like Contact-Email, # which doesn t change from bag to bag. Here we set bag-specific # tag values. job . add_tag ( bag-info.txt , Bag-Group-Identifier , TestGroup_001 ) job . add_tag ( aptrust-info.txt , Title , Workflow Test Files ) job . add_tag ( aptrust-info.txt , Description , Contains miscellaneous files for workflow testing. ) # Run the job and check the exit code. 0 indicates success. # Non-zero values indicate failure. exit_code = job . run () if exit_code == 0 puts Job completed else puts Job failed. Check the DART log for details. end","title":"Example: Ruby"},{"location":"users/scripting/#example-python","text":"Coming soon...","title":"Example: Python"},{"location":"users/bagit/","text":"BagIt Profiles While the BagIt specification describes the general requirements for a valid bag, BagIt profiles describe the tags, manifests, and tag manifests required to make a valid bag for a specific organization or purpose. DART uses BagIt profiles to produce bags that adhere to a profile, and to validate that bags do adhere to the profile. DART BagIt Profiles While the general specification for BagIt Profiles can be found on GitHub , DART's BagIt profiles differ from the published specification in the following ways: DART profiles use camel case identifiers with no hyphens or periods in attribute names. For example, the Allow-Fetch.txt in GitHub BagIt profiles is called allowFetchTxt in DART profiles. This is in part to simplify JavaScript attributes so they can be reference in dot notation, and in part because the nedb object database used in early versions of DART did not support attribute names containing dots. DART profiles include an id attribute with a UUID. This is used internally, while externally the bagItProfileIdentifier URL is used externally. DART profiles include the following additional boolean attributes: allowMiscTopLevelFiles which indicates whether files other than manifests and tag manifests are allowed in the bag's root directory. allowMiscDirectories which indicates whether directories other than /data and its children are allowed in the bag. tarDirMustMatchName which indicates whether the name of the unserialized bag must match the name of the serialized bag, minus the serialization extension. (That is, whether my_bag.tar must untar to my_bag, and my_bag.zip must unzip to my_bag.) DART includes the attribute baseProfileId for internal use, to know whether a user-created profile was based on an existing profile. DART includes the isBuiltIn attribute to indicate that a profile was built in to the application (usually through a setup module or migration). These profiles cannot be deleted. DART does not specify tagFilesRequired or tagFilesAllowed . DART BagIt profiles specify all tag requirements in a single list called tags while the GitHub BagIt spec defines them as nested objects with arbitrary names. The single list of uniform objects in the DART model makes tag definitions easier to manipulate. While tag definitions in the GitHub BagIt Profile spec include only the attributes required and values , DART tag definitions include the following attributes: id - A unique identifier in UUID format that DART uses internally. This allows users to edit tag definitions in the DART UI without the system losing track of which tag is being edited. The UUID is immutable while all other attributes are not. tagFile - The name of the tag file that contains the tag. This is a path relative to the bag root. For example, bag-info.txt or custom-tags/image-credits.txt . tagName - The name of the tag. For example, Source-Organization . required - A boolean indicating whether the tag is required. values - An option list of legal values. If this list is present and a tag contains a value that's not in the list, the value and the bag are invalid. defaultValue - A default value assigned by the user to the tag. DART's BagIt Profile editor allows users to specify default values to tags that will be consistent across bags. For example, users can define a default value to Source-Organization so they don't have to assign it repeatedly every time they create a new bag. userValue - The value of a tag to be written into or read from a tag file. Users can specify a userValue that overrides the defaultValue when they create a bag. When reading a bag, DART assigns the actual value of a tag to what was read from the bag. isBuiltIn - A boolean value indicating whether a tag definition is built in (as opposed to user-created). DART's BagIt Profile editor allows users to add custom tags to a published profile, such as the APTrust profile, while preventing them from deleting built-in tag definitions. Deleting a built-in tag definition such as Source-Organization would lead to DART generating invalid bags. help - Help text to describe the significance of the tag to the user. If present, the DART UI will display this message for the user's edification and delight. Built-in Profiles DART includes the following built-in profiles. Note that the BagIt Profile editor allows you to clone and customize each of these, though customization is limited to adding tags and tag files, and setting default tag values. APTrust - The standard APTrust BagIt profile. BTR - The Beyond the Repository BagIt profile, which will be accepted by a number of distributed digital preservation repositories. (Coming later in 2019.) DPN - The legacy DPN BagIt profile. This is used primarily for testing and development. Custom Profiles DART enables users to create new BagIt profiles from scratch, and to clone and modify existing profiles. See also: Creating BagIt Profiles , Customizing BagIt Profiles","title":"BagIt Profiles"},{"location":"users/bagit/#bagit-profiles","text":"While the BagIt specification describes the general requirements for a valid bag, BagIt profiles describe the tags, manifests, and tag manifests required to make a valid bag for a specific organization or purpose. DART uses BagIt profiles to produce bags that adhere to a profile, and to validate that bags do adhere to the profile.","title":"BagIt Profiles"},{"location":"users/bagit/#dart-bagit-profiles","text":"While the general specification for BagIt Profiles can be found on GitHub , DART's BagIt profiles differ from the published specification in the following ways: DART profiles use camel case identifiers with no hyphens or periods in attribute names. For example, the Allow-Fetch.txt in GitHub BagIt profiles is called allowFetchTxt in DART profiles. This is in part to simplify JavaScript attributes so they can be reference in dot notation, and in part because the nedb object database used in early versions of DART did not support attribute names containing dots. DART profiles include an id attribute with a UUID. This is used internally, while externally the bagItProfileIdentifier URL is used externally. DART profiles include the following additional boolean attributes: allowMiscTopLevelFiles which indicates whether files other than manifests and tag manifests are allowed in the bag's root directory. allowMiscDirectories which indicates whether directories other than /data and its children are allowed in the bag. tarDirMustMatchName which indicates whether the name of the unserialized bag must match the name of the serialized bag, minus the serialization extension. (That is, whether my_bag.tar must untar to my_bag, and my_bag.zip must unzip to my_bag.) DART includes the attribute baseProfileId for internal use, to know whether a user-created profile was based on an existing profile. DART includes the isBuiltIn attribute to indicate that a profile was built in to the application (usually through a setup module or migration). These profiles cannot be deleted. DART does not specify tagFilesRequired or tagFilesAllowed . DART BagIt profiles specify all tag requirements in a single list called tags while the GitHub BagIt spec defines them as nested objects with arbitrary names. The single list of uniform objects in the DART model makes tag definitions easier to manipulate. While tag definitions in the GitHub BagIt Profile spec include only the attributes required and values , DART tag definitions include the following attributes: id - A unique identifier in UUID format that DART uses internally. This allows users to edit tag definitions in the DART UI without the system losing track of which tag is being edited. The UUID is immutable while all other attributes are not. tagFile - The name of the tag file that contains the tag. This is a path relative to the bag root. For example, bag-info.txt or custom-tags/image-credits.txt . tagName - The name of the tag. For example, Source-Organization . required - A boolean indicating whether the tag is required. values - An option list of legal values. If this list is present and a tag contains a value that's not in the list, the value and the bag are invalid. defaultValue - A default value assigned by the user to the tag. DART's BagIt Profile editor allows users to specify default values to tags that will be consistent across bags. For example, users can define a default value to Source-Organization so they don't have to assign it repeatedly every time they create a new bag. userValue - The value of a tag to be written into or read from a tag file. Users can specify a userValue that overrides the defaultValue when they create a bag. When reading a bag, DART assigns the actual value of a tag to what was read from the bag. isBuiltIn - A boolean value indicating whether a tag definition is built in (as opposed to user-created). DART's BagIt Profile editor allows users to add custom tags to a published profile, such as the APTrust profile, while preventing them from deleting built-in tag definitions. Deleting a built-in tag definition such as Source-Organization would lead to DART generating invalid bags. help - Help text to describe the significance of the tag to the user. If present, the DART UI will display this message for the user's edification and delight.","title":"DART BagIt Profiles"},{"location":"users/bagit/#built-in-profiles","text":"DART includes the following built-in profiles. Note that the BagIt Profile editor allows you to clone and customize each of these, though customization is limited to adding tags and tag files, and setting default tag values. APTrust - The standard APTrust BagIt profile. BTR - The Beyond the Repository BagIt profile, which will be accepted by a number of distributed digital preservation repositories. (Coming later in 2019.) DPN - The legacy DPN BagIt profile. This is used primarily for testing and development.","title":"Built-in Profiles"},{"location":"users/bagit/#custom-profiles","text":"DART enables users to create new BagIt profiles from scratch, and to clone and modify existing profiles. See also: Creating BagIt Profiles , Customizing BagIt Profiles","title":"Custom Profiles"},{"location":"users/bagit/creating/","text":"Creating Profiles To create a new BagIt Profile: Choose Settings BagIt Profiles from the menu. Click the New button at the top of the profiles list. Select an option from the Base Profile list. Chose None if you want to create a new profile from scratch. Choose the name of an existing profile if you want to clone and modify an existing profile. Click the Create button. Note Cloning an existing BagIt profile can be useful if you're going to create bags on behalf of more than one organization or group. You can set different default values for tags such as Source-Organization or Contact-Email within each cloned profile, and then assign meaningful names such as APTrust Profile for Law Library and APTrust Profile for Engineering Library . Once you've created a new BagIt profile, you'll want to customize it using the built-in BagIt profile editor. See also: Customizing BagIt Profiles","title":"Creating Profiles"},{"location":"users/bagit/creating/#creating-profiles","text":"To create a new BagIt Profile: Choose Settings BagIt Profiles from the menu. Click the New button at the top of the profiles list. Select an option from the Base Profile list. Chose None if you want to create a new profile from scratch. Choose the name of an existing profile if you want to clone and modify an existing profile. Click the Create button. Note Cloning an existing BagIt profile can be useful if you're going to create bags on behalf of more than one organization or group. You can set different default values for tags such as Source-Organization or Contact-Email within each cloned profile, and then assign meaningful names such as APTrust Profile for Law Library and APTrust Profile for Engineering Library . Once you've created a new BagIt profile, you'll want to customize it using the built-in BagIt profile editor. See also: Customizing BagIt Profiles","title":"Creating Profiles"},{"location":"users/bagit/customizing/","text":"Customizing Profiles To customize a BagIt profile, click the name of the profile in the profiles list, or click new and follow the steps to create a BagIt profile . About The About tab of the BagIt profile editor enables you to set a name and description for your profile. Info The Info tab includes fields to edit the BagIt-Profile-Info section of the profile. This includes the profile's URL identifier. General The General tab includes information about which BagIt versions your profile accepts, whether to allow fetch.txt files, and whether to allow miscellaneous top level files (arbitrary tag files directly under the root directory) and miscellaneous directories outside the payload (/data) directory. Manifests The Manifests tab specifies which manifests and tag manifests your profile requires. You can select multiple options from each list by holding down the Control key on Windows or the Command key on Mac while you click. Serialization The Serialization tab allows you to specify whether serialization is required, optional, or forbidden, as well as which serialization formats are supported. You can also specify here whether serialized bags must deserialize to a directory whose name matches the serialized file name. (For example, my_bag.tar must untar to my_bag and my_bag.zip must unzip to my_bag.) Tag Files The Tag Files tab includes a drop-down list for editing the profile's tag files, and for adding new tag files. Adding a New Tag File To add a new tag file: Click Add New Tag File on the drop-down list. Enter a name for the tag file. If the name includes slashes, the tag file will be created in a subdirectory beneath the bag's root directory. For example, custom-tags/photo-credits.txt would be placed in the bag's custom-tags directory. Click the Save button. Editing a Tag File To edit a tag file: Click the Tag Files tab. Select the name of the file you want to edit. Adding a Tag To add a tag to a tag file, click the New Tag button (visible in the screenshot above), then follow the steps in Editing a Tag below. Editing a Tag To edit a tag: Click the name of the tag you want to edit. Set the appropriate values in the dialog. Tag Name - The name of the tag. This is required. Required - A Yes/No value indicating whether the tag must have a value for the bag to be considered valid. Values - An optional list of allowed values for this tag. Default Value - An optional default value for this tag. Help - An optional help message. This message will be displayed to users who are filling out a bag's tag values in DART. Click the Save button. Deleting a Tag To delete a tag, click the red X to the right of the tag name in the tag list view. If the tag does not have a red X, it is a required tag from a published profile and cannot be deleted. When you delete the last tag of a tag file, DART deletes the tag file as well. Deleting a Tag File To delete a tag file, delete all of the tags in the file. See Deleting a Tag above.","title":"Customizing Profiles"},{"location":"users/bagit/customizing/#customizing-profiles","text":"To customize a BagIt profile, click the name of the profile in the profiles list, or click new and follow the steps to create a BagIt profile .","title":"Customizing Profiles"},{"location":"users/bagit/customizing/#about","text":"The About tab of the BagIt profile editor enables you to set a name and description for your profile.","title":"About"},{"location":"users/bagit/customizing/#info","text":"The Info tab includes fields to edit the BagIt-Profile-Info section of the profile. This includes the profile's URL identifier.","title":"Info"},{"location":"users/bagit/customizing/#general","text":"The General tab includes information about which BagIt versions your profile accepts, whether to allow fetch.txt files, and whether to allow miscellaneous top level files (arbitrary tag files directly under the root directory) and miscellaneous directories outside the payload (/data) directory.","title":"General"},{"location":"users/bagit/customizing/#manifests","text":"The Manifests tab specifies which manifests and tag manifests your profile requires. You can select multiple options from each list by holding down the Control key on Windows or the Command key on Mac while you click.","title":"Manifests"},{"location":"users/bagit/customizing/#serialization","text":"The Serialization tab allows you to specify whether serialization is required, optional, or forbidden, as well as which serialization formats are supported. You can also specify here whether serialized bags must deserialize to a directory whose name matches the serialized file name. (For example, my_bag.tar must untar to my_bag and my_bag.zip must unzip to my_bag.)","title":"Serialization"},{"location":"users/bagit/customizing/#tag-files","text":"The Tag Files tab includes a drop-down list for editing the profile's tag files, and for adding new tag files.","title":"Tag Files"},{"location":"users/bagit/customizing/#adding-a-new-tag-file","text":"To add a new tag file: Click Add New Tag File on the drop-down list. Enter a name for the tag file. If the name includes slashes, the tag file will be created in a subdirectory beneath the bag's root directory. For example, custom-tags/photo-credits.txt would be placed in the bag's custom-tags directory. Click the Save button.","title":"Adding a New Tag File"},{"location":"users/bagit/customizing/#editing-a-tag-file","text":"To edit a tag file: Click the Tag Files tab. Select the name of the file you want to edit.","title":"Editing a Tag File"},{"location":"users/bagit/customizing/#adding-a-tag","text":"To add a tag to a tag file, click the New Tag button (visible in the screenshot above), then follow the steps in Editing a Tag below.","title":"Adding a Tag"},{"location":"users/bagit/customizing/#editing-a-tag","text":"To edit a tag: Click the name of the tag you want to edit. Set the appropriate values in the dialog. Tag Name - The name of the tag. This is required. Required - A Yes/No value indicating whether the tag must have a value for the bag to be considered valid. Values - An optional list of allowed values for this tag. Default Value - An optional default value for this tag. Help - An optional help message. This message will be displayed to users who are filling out a bag's tag values in DART. Click the Save button.","title":"Editing a Tag"},{"location":"users/bagit/customizing/#deleting-a-tag","text":"To delete a tag, click the red X to the right of the tag name in the tag list view. If the tag does not have a red X, it is a required tag from a published profile and cannot be deleted. When you delete the last tag of a tag file, DART deletes the tag file as well.","title":"Deleting a Tag"},{"location":"users/bagit/customizing/#deleting-a-tag-file","text":"To delete a tag file, delete all of the tags in the file. See Deleting a Tag above.","title":"Deleting a Tag File"},{"location":"users/bagit/exporting/","text":"Exporting Profiles This feature isn't implemented yet. It will allow users to export DART BagIt profiles to standard BagIt Profiles as defined in this GitHub repo .","title":"Exporting Profiles"},{"location":"users/bagit/exporting/#exporting-profiles","text":"This feature isn't implemented yet. It will allow users to export DART BagIt profiles to standard BagIt Profiles as defined in this GitHub repo .","title":"Exporting Profiles"},{"location":"users/bagit/importing/","text":"Importing Profiles This feature isn't implemented yet. Currently, the only ways to get profiles into DART are: migrations setup modules creating your own through the UI","title":"Importing Profiles"},{"location":"users/bagit/importing/#importing-profiles","text":"This feature isn't implemented yet. Currently, the only ways to get profiles into DART are: migrations setup modules creating your own through the UI","title":"Importing Profiles"},{"location":"users/jobs/","text":"Jobs A job is a set of actions that may include one or more of the following: Packaging a number of files into a defined format, such as BagIt, tar, etc. Validating the package. Uploading the package to one or more remote locations. DART was initially designed for APTrust depositors to bag files according to the APTrust BagIt profile, validate the bags, and then send them to an S3 bucket for ingest into APTrust's preservation repository. DART plugin architecture will allow it to handle similary patterned jobs that use different packaging formats and network protocols such as zip, rar, or parchive formats sent via FTP or rsync. The process for creating and running jobs invlolves these steps: Adding files . Choosing a package format . Adding metadata . Choosing upload targets . Reviewing and running the job . For infomation about developing DART plugins, see the Plugins Developer Documentation . Jobs and Workflows Jobs can be converted to workflows. A workflow is essentially a job template that can be run in the DART UI or from the command line. A workflow enables you to run a number of jobs that all follow the same pattern (same packaging format, same default metadata values, and same upload targets).","title":"Jobs"},{"location":"users/jobs/#jobs","text":"A job is a set of actions that may include one or more of the following: Packaging a number of files into a defined format, such as BagIt, tar, etc. Validating the package. Uploading the package to one or more remote locations. DART was initially designed for APTrust depositors to bag files according to the APTrust BagIt profile, validate the bags, and then send them to an S3 bucket for ingest into APTrust's preservation repository. DART plugin architecture will allow it to handle similary patterned jobs that use different packaging formats and network protocols such as zip, rar, or parchive formats sent via FTP or rsync. The process for creating and running jobs invlolves these steps: Adding files . Choosing a package format . Adding metadata . Choosing upload targets . Reviewing and running the job . For infomation about developing DART plugins, see the Plugins Developer Documentation .","title":"Jobs"},{"location":"users/jobs/#jobs-and-workflows","text":"Jobs can be converted to workflows. A workflow is essentially a job template that can be run in the DART UI or from the command line. A workflow enables you to run a number of jobs that all follow the same pattern (same packaging format, same default metadata values, and same upload targets).","title":"Jobs and Workflows"},{"location":"users/jobs/delete/","text":"Deleting Jobs To delete a job: Choose Jobs List from the menu. Click on the job you want to delete. Click the red Delete button in the bottom left corner of the Job files page.","title":"Deleting Jobs"},{"location":"users/jobs/delete/#deleting-jobs","text":"To delete a job: Choose Jobs List from the menu. Click on the job you want to delete. Click the red Delete button in the bottom left corner of the Job files page.","title":"Deleting Jobs"},{"location":"users/jobs/files/","text":"Adding Files After you create a new job or click on a job in the Jobs list, you'll see the files page. You can add files to a job by dragging them into the drop zone, which is outlined in blue. The files window shows the total number of files and directories you've added, and total size of all the files. After adding files and directories, click the Next button to move on to the Packaging step. Note that you can also delete the job from this screen. Removing Files To remove a file from the job, click the red X in the row of the file you want to delete.","title":"Adding Files"},{"location":"users/jobs/files/#adding-files","text":"After you create a new job or click on a job in the Jobs list, you'll see the files page. You can add files to a job by dragging them into the drop zone, which is outlined in blue. The files window shows the total number of files and directories you've added, and total size of all the files. After adding files and directories, click the Next button to move on to the Packaging step. Note that you can also delete the job from this screen.","title":"Adding Files"},{"location":"users/jobs/files/#removing-files","text":"To remove a file from the job, click the red X in the row of the file you want to delete.","title":"Removing Files"},{"location":"users/jobs/list/","text":"Listing Jobs To list all jobs, Choose Jobs List from the menu. The list shows the job name and information about when it was last packaged, validated, and/or uploaded. Click on any job in the list to view it. On the following screen, you'll be able to edit or delete the job.","title":"Listing Jobs"},{"location":"users/jobs/list/#listing-jobs","text":"To list all jobs, Choose Jobs List from the menu. The list shows the job name and information about when it was last packaged, validated, and/or uploaded. Click on any job in the list to view it. On the following screen, you'll be able to edit or delete the job.","title":"Listing Jobs"},{"location":"users/jobs/metadata/","text":"Metadata You'll see the job metadata screen if you chose the BagIt packaging format on the previous screen. This screen allows you to enter values for tags that will go into BagIt tag files. By default, this screen only shows tags whose values are not already filled in by default values. Default values come from two places: Default tag values you've entered into your local BagIt profiles. See the Editing a Tag section for information about setting default values. Auto-filled values calculated by DART when it creates the bag, such as the Payload-Oxum, Bagging-Software, and Bagging-Date. If you want to edit tags with pre-set default values, click the Show All Tags button in the top right corner of the page. Adding Custom Tags You can add a custom tag to a bag by clicking the Add New Tag button at the top of the page. Note that adding extra tags to a bag generally will not cause the bag to be invalid. The only exception to this rule is adding tags that the BagIt specification says may not be repeated, such as the Payload-Oxum tag.","title":"Metadata"},{"location":"users/jobs/metadata/#metadata","text":"You'll see the job metadata screen if you chose the BagIt packaging format on the previous screen. This screen allows you to enter values for tags that will go into BagIt tag files. By default, this screen only shows tags whose values are not already filled in by default values. Default values come from two places: Default tag values you've entered into your local BagIt profiles. See the Editing a Tag section for information about setting default values. Auto-filled values calculated by DART when it creates the bag, such as the Payload-Oxum, Bagging-Software, and Bagging-Date. If you want to edit tags with pre-set default values, click the Show All Tags button in the top right corner of the page.","title":"Metadata"},{"location":"users/jobs/metadata/#adding-custom-tags","text":"You can add a custom tag to a bag by clicking the Add New Tag button at the top of the page. Note that adding extra tags to a bag generally will not cause the bag to be invalid. The only exception to this rule is adding tags that the BagIt specification says may not be repeated, such as the Payload-Oxum tag.","title":"Adding Custom Tags"},{"location":"users/jobs/packaging/","text":"Packaging The packaging screen incudes the following options: Package Format - Choose how you want your files to be packaged. The following options are available: None - Choose this option if you don't want to package your files at all. This option makes sense when you want upload files without first bagging or tarring them. BagIt - Choose this if you want to bag your files in BagIt format. Directory - Choose if you want to copy all of your files into a single directory. This will not move or delete the original files. Tar - Choose this if you want to pack your files into a single tar file. BagIt Profile - This option appears when you choose BagIt as the package format. Note that you can have structurally identical BagIt profiles with different sets of default values. See Creating BagIt Profiles for more information. Package Name - Type the name of the package you want to create. DART will create a package with this file name. Note that some repositories, including APTrust * , have required naming conventions, and most discourage the use of non-printable characters in package names. Output Path - This is where DART will put the local copy of the package that it builds. Notice that this field is filled in automatically as you type the package name. Unless you have good reason, you should not manually edit this field. * APTrust bag names should begin with your organization identifier, followed by a dot and a unique name. For example, virginia.edu.photos-2019-07-21.","title":"Packaging"},{"location":"users/jobs/packaging/#packaging","text":"The packaging screen incudes the following options: Package Format - Choose how you want your files to be packaged. The following options are available: None - Choose this option if you don't want to package your files at all. This option makes sense when you want upload files without first bagging or tarring them. BagIt - Choose this if you want to bag your files in BagIt format. Directory - Choose if you want to copy all of your files into a single directory. This will not move or delete the original files. Tar - Choose this if you want to pack your files into a single tar file. BagIt Profile - This option appears when you choose BagIt as the package format. Note that you can have structurally identical BagIt profiles with different sets of default values. See Creating BagIt Profiles for more information. Package Name - Type the name of the package you want to create. DART will create a package with this file name. Note that some repositories, including APTrust * , have required naming conventions, and most discourage the use of non-printable characters in package names. Output Path - This is where DART will put the local copy of the package that it builds. Notice that this field is filled in automatically as you type the package name. Unless you have good reason, you should not manually edit this field. * APTrust bag names should begin with your organization identifier, followed by a dot and a unique name. For example, virginia.edu.photos-2019-07-21.","title":"Packaging"},{"location":"users/jobs/run/","text":"Run Your Job After defining the files your job will work with and the optional packaging, metadata, and upload steps, the Run page displays a summary of the work that DART will perform. Review the details to ensure that everything looks right, then click the Run button to run the job. After clicking run, your job will begin. DART runs each job in a separate process, which provides a number of benefits: You can run many jobs at once. If any job encounters errors, it will not affect the other running jobs. You can continue to use DART while background jobs run. Nothing you do in DART, except quitting the application, will affect the running jobs. After clicking Run , you'll see the progress of each operation on screen. Striped blue bars indicate a work in progress. A green bar represents a completed operation, while a red bar indicates a failure. If a job includes multiple uploads, you'll see one progress bar for each upload. Large jobs may take a long time to complete. As long as jobs are running, you can continue to work in DART without affecting their progress. You'll see a badge like this in the upper right corner of the menu showing the number of running background jobs: Progress Bar Accuracy The progress bars for packaging and validation are accurate to within a few seconds of actual operation time. The progress bar for uploads usually displays more progress than has actually been completed. This is because DART can know exactly how many bytes of an upload it has prepared to send, but not how many the upload target has received. The upload progress bar displays the number of bytes prepared, and will appear to stall at around 98% completion on large uploads, as it awaits transferral of the final chunk of data. In a 100 MB upload, that final chunk may include only 1 MB of data, taking a few seconds to transfer. In a 5 TB upload to S3, the final chunk can be 535 MB and can take many minutes to complete. Creating a Workflow from a Job If you've created a successful job that you want to be the pattern for future jobs, click the Create Workflow button to create a repeatable workflow that can run new files through the same set of steps that this job just completed.","title":"Run Your Job"},{"location":"users/jobs/run/#run-your-job","text":"After defining the files your job will work with and the optional packaging, metadata, and upload steps, the Run page displays a summary of the work that DART will perform. Review the details to ensure that everything looks right, then click the Run button to run the job. After clicking run, your job will begin. DART runs each job in a separate process, which provides a number of benefits: You can run many jobs at once. If any job encounters errors, it will not affect the other running jobs. You can continue to use DART while background jobs run. Nothing you do in DART, except quitting the application, will affect the running jobs. After clicking Run , you'll see the progress of each operation on screen. Striped blue bars indicate a work in progress. A green bar represents a completed operation, while a red bar indicates a failure. If a job includes multiple uploads, you'll see one progress bar for each upload. Large jobs may take a long time to complete. As long as jobs are running, you can continue to work in DART without affecting their progress. You'll see a badge like this in the upper right corner of the menu showing the number of running background jobs:","title":"Run Your Job"},{"location":"users/jobs/run/#progress-bar-accuracy","text":"The progress bars for packaging and validation are accurate to within a few seconds of actual operation time. The progress bar for uploads usually displays more progress than has actually been completed. This is because DART can know exactly how many bytes of an upload it has prepared to send, but not how many the upload target has received. The upload progress bar displays the number of bytes prepared, and will appear to stall at around 98% completion on large uploads, as it awaits transferral of the final chunk of data. In a 100 MB upload, that final chunk may include only 1 MB of data, taking a few seconds to transfer. In a 5 TB upload to S3, the final chunk can be 535 MB and can take many minutes to complete.","title":"Progress Bar Accuracy"},{"location":"users/jobs/run/#creating-a-workflow-from-a-job","text":"If you've created a successful job that you want to be the pattern for future jobs, click the Create Workflow button to create a repeatable workflow that can run new files through the same set of steps that this job just completed.","title":"Creating a Workflow from a Job"},{"location":"users/jobs/upload/","text":"Uploads You can specify one or more upload targets on the uploads page. Simply check the box beside each target you want to upload to. The list of available targets comes from the Storage Service settings in your local DART installation. You can add as many storage services as you like. To appear in the list of upload targets, a storage service must include a protocol, URL, login, and password, and it must have the Allows Upload set to Yes . If some of your storage services do not appear in the list, check to see they meet all of these criteria.","title":"Uploads"},{"location":"users/jobs/upload/#uploads","text":"You can specify one or more upload targets on the uploads page. Simply check the box beside each target you want to upload to. The list of available targets comes from the Storage Service settings in your local DART installation. You can add as many storage services as you like. To appear in the list of upload targets, a storage service must include a protocol, URL, login, and password, and it must have the Allows Upload set to Yes . If some of your storage services do not appear in the list, check to see they meet all of these criteria.","title":"Uploads"},{"location":"users/settings/","text":"Settings DART includes the following settings: App Settings include information such as your organization name (used when creating bags) and your default output directory (to which bags are written). Internal Settings are read-only settings that you may occasionally need to examine when tracing problems. Remote Repositories describe how to connect to remote preservation repositories that ingest the materials you upload. Storage Services describe how to connect to drop-off and pick up points, such as S3 buckets or FTP services. These are usually temporary storage points used to drop off materials for ingest or to pick up items restored by a preservation repository.","title":"Settings"},{"location":"users/settings/#settings","text":"DART includes the following settings: App Settings include information such as your organization name (used when creating bags) and your default output directory (to which bags are written). Internal Settings are read-only settings that you may occasionally need to examine when tracing problems. Remote Repositories describe how to connect to remote preservation repositories that ingest the materials you upload. Storage Services describe how to connect to drop-off and pick up points, such as S3 buckets or FTP services. These are usually temporary storage points used to drop off materials for ingest or to pick up items restored by a preservation repository.","title":"Settings"},{"location":"users/settings/app_settings/","text":"App Settings App Settings contain DART's application-wide settings. These may be used when creating bags and other packages. To view the list of all settings, select Settings App Settings from the main menu. Editing App Settings Click on any setting in the list to edit it. Note that some essential settings, such as Bagging Directory and Institution Domain cannot be renamed or deleted, though their values can be changed.","title":"App Settings"},{"location":"users/settings/app_settings/#app-settings","text":"App Settings contain DART's application-wide settings. These may be used when creating bags and other packages. To view the list of all settings, select Settings App Settings from the main menu.","title":"App Settings"},{"location":"users/settings/app_settings/#editing-app-settings","text":"Click on any setting in the list to edit it. Note that some essential settings, such as Bagging Directory and Institution Domain cannot be renamed or deleted, though their values can be changed.","title":"Editing App Settings"},{"location":"users/settings/internal_settings/","text":"Internal Settings Internal Settings contain configuration information that users cannot edit. These settings are created by plugins, setup packages, and software updates. Though you cannot change them, knowing their values may be helpful to DART users and developers.","title":"Internal Settings"},{"location":"users/settings/internal_settings/#internal-settings","text":"Internal Settings contain configuration information that users cannot edit. These settings are created by plugins, setup packages, and software updates. Though you cannot change them, knowing their values may be helpful to DART users and developers.","title":"Internal Settings"},{"location":"users/settings/remote_repositories/","text":"Remote Repositories Remote repositories are services to which you upload data for preservation. DART can query remote repositories to show the status of items you've uploaded for ingest, provided the following three conditions are met: The remote repository has a REST API. Most do, including APTrust, Fedora, DSpace, and many others. DART has a plugin that knows how to talk to the repository. (On initial release, the only plugin is for APTrust, but more may be coming.) You have a Remote Repository setting that points to the correct URL and contains valid login credentials. Listing Remote Repositories To view the list of Remote Repository settings, choose Settings Remote Repositories from the menu. Editing Remote Repositories Click on any repository in the list to edit it, or click the New button to create a new one. Description of Settings Name The name of the remote repository. This is required. It can be anything you want, and chaning it will not affect the behavior or availability of the repository. URL The base URL of the repository's REST API. This may or may not include path information. For example, https://example.com has no path information, while https://example.com/api/v2/ does include path info. Check with your repository to get the correct URL. Plugin Choose the plugin that can connect to your repository. If you don't see the plugin in the list, it has not been installed. Note that at the time of DART's initial release, the only available plugin is APTrustClient . User ID Enter the user ID you use to connect to the repository's REST API. If the API only uses a token and no user ID, leave this blank. API Token Enter the API token used to connect to this repository. You'll have to get a token from the repository itself. Login Extra This field is generally left blank. If your repository uses it, they should provide instructions on how to fill this in.","title":"Remote Repositories"},{"location":"users/settings/remote_repositories/#remote-repositories","text":"Remote repositories are services to which you upload data for preservation. DART can query remote repositories to show the status of items you've uploaded for ingest, provided the following three conditions are met: The remote repository has a REST API. Most do, including APTrust, Fedora, DSpace, and many others. DART has a plugin that knows how to talk to the repository. (On initial release, the only plugin is for APTrust, but more may be coming.) You have a Remote Repository setting that points to the correct URL and contains valid login credentials.","title":"Remote Repositories"},{"location":"users/settings/remote_repositories/#listing-remote-repositories","text":"To view the list of Remote Repository settings, choose Settings Remote Repositories from the menu.","title":"Listing Remote Repositories"},{"location":"users/settings/remote_repositories/#editing-remote-repositories","text":"Click on any repository in the list to edit it, or click the New button to create a new one.","title":"Editing Remote Repositories"},{"location":"users/settings/remote_repositories/#description-of-settings","text":"","title":"Description of Settings"},{"location":"users/settings/remote_repositories/#name","text":"The name of the remote repository. This is required. It can be anything you want, and chaning it will not affect the behavior or availability of the repository.","title":"Name"},{"location":"users/settings/remote_repositories/#url","text":"The base URL of the repository's REST API. This may or may not include path information. For example, https://example.com has no path information, while https://example.com/api/v2/ does include path info. Check with your repository to get the correct URL.","title":"URL"},{"location":"users/settings/remote_repositories/#plugin","text":"Choose the plugin that can connect to your repository. If you don't see the plugin in the list, it has not been installed. Note that at the time of DART's initial release, the only available plugin is APTrustClient .","title":"Plugin"},{"location":"users/settings/remote_repositories/#user-id","text":"Enter the user ID you use to connect to the repository's REST API. If the API only uses a token and no user ID, leave this blank.","title":"User ID"},{"location":"users/settings/remote_repositories/#api-token","text":"Enter the API token used to connect to this repository. You'll have to get a token from the repository itself.","title":"API Token"},{"location":"users/settings/remote_repositories/#login-extra","text":"This field is generally left blank. If your repository uses it, they should provide instructions on how to fill this in.","title":"Login Extra"},{"location":"users/settings/storage_services/","text":"Storage Services Storage services are not repositories! They are pickup and drop-off points for materials going into or coming out of repositories. Some repositories ask depositors to upload materials into an S3 bucket or an SFTP folder for ingest, and restore materials to a similar bucket or folder for depositors to retrieve. Storage services allow DART to connect to these pickup and drop-off points. Note, however, that you're free to send data to and from these storage services even if they're not ultimately bound for a preservation repository. Listing Storage Services To list all storage services, choose Settings Storage Services from the menu. Editing Storage Services Click any storage servicei in the list to edit it. Description of Settings Name The name of the service. Choose a name that's meaningful to you and that differentiates this service from others. You can change the name at any time without affecting the bevavior or availability of the service. Description A description of this service. Protocol Choose the network protocol used to communicate with this service. Note: At launch, DART supports only the S3 protocol. Host Enter the name or IP address of the service host. Do not include protocol prefixes like https:// or ftp:// . For example, the host name for Amazon's S3 service is s3.amazonaws.com . A locally hosted service may be s3.example.com or ftp.example.com . You can also enter an IP address here such as 127.0.0.1 . Port The port to connect to. In most cases, you'll want to leave this at 0 (zero). Set this only if the service is running on a non-standard port number. Bucket The name of the bucket you'll be uploading into or downloading from on the remote host. For the S3 protocol, this will be a bucket name like aptrust.dart.test . For protocols like FTP and rsync, this will be a directory name like uploads/ingest/ or downloads/restore . Allows Upload Choose Yes if this service allows you to upload files, No otherwise. Info This setting is important. When you run a job, DART gives you a choice of storage services to which to send your files. DART will show only those services where Allows Upload is set to Yes . Allows Download Choose Yes if this service allows you to download files, No otherwise. Info While DART does not support downloads in its initial release, it may support them in a future release. Login Enter your login name for the service. For FTP and rsync services, this will typically be a user name. For S3 services, it will be an access key ID. For S3 services, you may want to keep your access keys in an environment variable. If you choose to do so, you can enter env: followed by the name of the environment variable here and DART will pull the setting from the environment at run time. For example, if you keep your AWS access key id in an environment variable called AWS_ACCESS_KEY_ID, then enter env:AWS_ACCESS_KEY_ID . Password Enter your password for the service. For FTP and rsync services, this will typically be an actual passowrd. For S3 services, it will be an secret access key. As with the Login field above, you can set this to reference an environment variable using the env: pattern. For example, env:AWS_SECRET_ACCESS_KEY . Login Extra This field is typically not used. If your storage service requires it, the plugin documentation should describe what to enter here. Otherwise, leave this field blank.","title":"Storage Services"},{"location":"users/settings/storage_services/#storage-services","text":"Storage services are not repositories! They are pickup and drop-off points for materials going into or coming out of repositories. Some repositories ask depositors to upload materials into an S3 bucket or an SFTP folder for ingest, and restore materials to a similar bucket or folder for depositors to retrieve. Storage services allow DART to connect to these pickup and drop-off points. Note, however, that you're free to send data to and from these storage services even if they're not ultimately bound for a preservation repository.","title":"Storage Services"},{"location":"users/settings/storage_services/#listing-storage-services","text":"To list all storage services, choose Settings Storage Services from the menu.","title":"Listing Storage Services"},{"location":"users/settings/storage_services/#editing-storage-services","text":"Click any storage servicei in the list to edit it.","title":"Editing Storage Services"},{"location":"users/settings/storage_services/#description-of-settings","text":"","title":"Description of Settings"},{"location":"users/settings/storage_services/#name","text":"The name of the service. Choose a name that's meaningful to you and that differentiates this service from others. You can change the name at any time without affecting the bevavior or availability of the service.","title":"Name"},{"location":"users/settings/storage_services/#description","text":"A description of this service.","title":"Description"},{"location":"users/settings/storage_services/#protocol","text":"Choose the network protocol used to communicate with this service. Note: At launch, DART supports only the S3 protocol.","title":"Protocol"},{"location":"users/settings/storage_services/#host","text":"Enter the name or IP address of the service host. Do not include protocol prefixes like https:// or ftp:// . For example, the host name for Amazon's S3 service is s3.amazonaws.com . A locally hosted service may be s3.example.com or ftp.example.com . You can also enter an IP address here such as 127.0.0.1 .","title":"Host"},{"location":"users/settings/storage_services/#port","text":"The port to connect to. In most cases, you'll want to leave this at 0 (zero). Set this only if the service is running on a non-standard port number.","title":"Port"},{"location":"users/settings/storage_services/#bucket","text":"The name of the bucket you'll be uploading into or downloading from on the remote host. For the S3 protocol, this will be a bucket name like aptrust.dart.test . For protocols like FTP and rsync, this will be a directory name like uploads/ingest/ or downloads/restore .","title":"Bucket"},{"location":"users/settings/storage_services/#allows-upload","text":"Choose Yes if this service allows you to upload files, No otherwise. Info This setting is important. When you run a job, DART gives you a choice of storage services to which to send your files. DART will show only those services where Allows Upload is set to Yes .","title":"Allows Upload"},{"location":"users/settings/storage_services/#allows-download","text":"Choose Yes if this service allows you to download files, No otherwise. Info While DART does not support downloads in its initial release, it may support them in a future release.","title":"Allows Download"},{"location":"users/settings/storage_services/#login","text":"Enter your login name for the service. For FTP and rsync services, this will typically be a user name. For S3 services, it will be an access key ID. For S3 services, you may want to keep your access keys in an environment variable. If you choose to do so, you can enter env: followed by the name of the environment variable here and DART will pull the setting from the environment at run time. For example, if you keep your AWS access key id in an environment variable called AWS_ACCESS_KEY_ID, then enter env:AWS_ACCESS_KEY_ID .","title":"Login"},{"location":"users/settings/storage_services/#password","text":"Enter your password for the service. For FTP and rsync services, this will typically be an actual passowrd. For S3 services, it will be an secret access key. As with the Login field above, you can set this to reference an environment variable using the env: pattern. For example, env:AWS_SECRET_ACCESS_KEY .","title":"Password"},{"location":"users/settings/storage_services/#login-extra","text":"This field is typically not used. If your storage service requires it, the plugin documentation should describe what to enter here. Otherwise, leave this field blank.","title":"Login Extra"},{"location":"users/workflows/","text":"Workflows A workflow is a set of packaging, validation, and/or upload operations that you define as a template to be run on any sets of files you choose. Workflows ensure that the exact same set of steps is run on each set of files. DART can run workflows from the UI and from the command line, which means you can create scripts that use workflows to package and upload materials. Defining a Workflow DART provides two ways to define a workflow: from a job or from scratch. Creating a Workflow from a Job The easiest way to create a workflow is to first create a job that includes all of the operations you want to include, run the job to ensure it works, then click the Convert to Workflow button on the Review and Run screen. Creating a Workflow from Scratch To create a workflow from scratch: Choose Workflows New from the menu. Fill in the details. The Name is required and should describe what the workflow will do. This name will appear on the Workflow menu, and scripted tasks will use this name to reference the workflow. (See #2 under Tips for Workflows below.) The Description is for your internal use. Choose the Package Format that suits your needs. If you chose BagIt as the Package Format, choose which BagIt Profile you want to use to build the bag. (See #1 under Tips for Workflows below.) Choose the destination to which you want to upload the packaged files. Note that only Storage Services where Allows Upload is set to Yes will appear in the Upload To list. Click Save , and remember that you can edit or delete this workflow later. Tips for Workflows Use customized BagIt profiles. DART lets you clone the base version of a BagIt profile and then add your own tag default values, so that you don't have to re-enter those values each time you create a new bag. For example, most BagIt profiles require a value for the Source-Organization tag, and typically, this value will be the same for every bag you create. Most profiles also require a number of other tags that may rarely or never change from bag to bag. For example, most depositors will set the same Access and Storage-Option values for 99% of the bags they upload to APTrust. Including in your workflow a custom BagIt profile with pre-set default values will save you having to re-enter common tag values, while still allowing you to override them when necessary. Use meaningful names for your workflows. Many repositories include both a staging environment and a production environment. You may create workflows that are identical except that one pushes packages into the staging environment while the other pushes to production. DART lets you run workflows directly from the workflow menu. Meaningful names help uses choose the right workflow and understand what the consequences of the actions they are about to take.","title":"Workflows"},{"location":"users/workflows/#workflows","text":"A workflow is a set of packaging, validation, and/or upload operations that you define as a template to be run on any sets of files you choose. Workflows ensure that the exact same set of steps is run on each set of files. DART can run workflows from the UI and from the command line, which means you can create scripts that use workflows to package and upload materials.","title":"Workflows"},{"location":"users/workflows/#defining-a-workflow","text":"DART provides two ways to define a workflow: from a job or from scratch.","title":"Defining a Workflow"},{"location":"users/workflows/#creating-a-workflow-from-a-job","text":"The easiest way to create a workflow is to first create a job that includes all of the operations you want to include, run the job to ensure it works, then click the Convert to Workflow button on the Review and Run screen.","title":"Creating a Workflow from a Job"},{"location":"users/workflows/#creating-a-workflow-from-scratch","text":"To create a workflow from scratch: Choose Workflows New from the menu. Fill in the details. The Name is required and should describe what the workflow will do. This name will appear on the Workflow menu, and scripted tasks will use this name to reference the workflow. (See #2 under Tips for Workflows below.) The Description is for your internal use. Choose the Package Format that suits your needs. If you chose BagIt as the Package Format, choose which BagIt Profile you want to use to build the bag. (See #1 under Tips for Workflows below.) Choose the destination to which you want to upload the packaged files. Note that only Storage Services where Allows Upload is set to Yes will appear in the Upload To list. Click Save , and remember that you can edit or delete this workflow later.","title":"Creating a Workflow from Scratch"},{"location":"users/workflows/#tips-for-workflows","text":"Use customized BagIt profiles. DART lets you clone the base version of a BagIt profile and then add your own tag default values, so that you don't have to re-enter those values each time you create a new bag. For example, most BagIt profiles require a value for the Source-Organization tag, and typically, this value will be the same for every bag you create. Most profiles also require a number of other tags that may rarely or never change from bag to bag. For example, most depositors will set the same Access and Storage-Option values for 99% of the bags they upload to APTrust. Including in your workflow a custom BagIt profile with pre-set default values will save you having to re-enter common tag values, while still allowing you to override them when necessary. Use meaningful names for your workflows. Many repositories include both a staging environment and a production environment. You may create workflows that are identical except that one pushes packages into the staging environment while the other pushes to production. DART lets you run workflows directly from the workflow menu. Meaningful names help uses choose the right workflow and understand what the consequences of the actions they are about to take.","title":"Tips for Workflows"},{"location":"users/workflows/job_params/","text":"Job Params The JobParams object is a simple JSON structure that gives a DART command-line job four essential pieces of information it needs to run a job. These are: workflowName - The name of the workflow to run. packageName - The name of the package to create. files - A list of files and/or directories to put into the package and/or upload to a remote server. If the workflow incudes one or more upload operations but no packaging operation, the files will be uploaded directly. tags - A list of tag names and values to add to the package. Below is sample JobParams JSON describing which files should be passed through the \"APTrust Demo System Workflow\" and what tag values should be applied. In this case, two directories and one file will be packaged with four custom-defined tags. { workflowName : APTrust Demo System Workflow , packageName : test.edu.my_files.tar , files : [ /path/to/first/directory , /path/to/second/directory , /path/to/some/document.pdf ], tags : [ { tagFile : bag-info.txt , tagName : Bag-Group-Identifier , userValue : Photos_2019 }, { tagFile : aptrust-info.txt , tagName : Title , userValue : Photos from 2019 }, { tagFile : aptrust-info.txt , tagName : Description , userValue : What I did with my summer vacation. }, { tagFile : custom/legal-info.txt , tagName : License , userValue : https://creativecommons.org/publicdomain/zero/1.0/ } ] } Let's assume the hypothetical \"APTrust Demo System Workflow\" includes the following steps: Package all files according to our customized version of the APTrust BagIt profile. Validate the resulting bag. Upload the bag to our ingest bucket for the APTrust Demo system. Upload the bag to the S3 bucket in our local owncloud S3 service. Passing the JSON above to the DART command line application will result in the following: The file /path/to/some/document.pdf and the contents of the directories /path/to/first/directory and /path/to/second/directory will be packed into the data directory of a new BagIt bag. DART will create and populate all of the tag files required by the APTrust BagIt profile. It will use the default values saved in your locally customized version of the profile where possible, overriding the defaults with the bag-specific values supplied in the JSON. Note Note that certain BagIt tag values, such as Source-Organization, Contact-Email, etc. will not change from bag to bag, so it makes sense to set default values for them in your customized profile. Other values, such as bag title and description, will change for every bag, so it makes sense to set them in the JobParams JSON. DART will save the entire package to a file whose name matches the package name. DART will write the file into your bagging directory, which is usually a directory called .dart under your home directory. You can verify (and change) the name of your bagging directory by choosing App Settings from the DART menu and clicking on the setting called Bagging Directory . DART will verify the bag according to the APTrust BagIt profile (or whichever profile the Workflow specified). DART will upload the verified bag to APTrust's S3 ingest bucket. DART will upload the verified bag to your local ownCloud S3 bucket. See also: Workflows , Command Line Reference , Scripting with DART Further Reading You'll find more detailed developer documentation for the JobParams object in our DART API documentation .","title":"Job Params"},{"location":"users/workflows/job_params/#job-params","text":"The JobParams object is a simple JSON structure that gives a DART command-line job four essential pieces of information it needs to run a job. These are: workflowName - The name of the workflow to run. packageName - The name of the package to create. files - A list of files and/or directories to put into the package and/or upload to a remote server. If the workflow incudes one or more upload operations but no packaging operation, the files will be uploaded directly. tags - A list of tag names and values to add to the package. Below is sample JobParams JSON describing which files should be passed through the \"APTrust Demo System Workflow\" and what tag values should be applied. In this case, two directories and one file will be packaged with four custom-defined tags. { workflowName : APTrust Demo System Workflow , packageName : test.edu.my_files.tar , files : [ /path/to/first/directory , /path/to/second/directory , /path/to/some/document.pdf ], tags : [ { tagFile : bag-info.txt , tagName : Bag-Group-Identifier , userValue : Photos_2019 }, { tagFile : aptrust-info.txt , tagName : Title , userValue : Photos from 2019 }, { tagFile : aptrust-info.txt , tagName : Description , userValue : What I did with my summer vacation. }, { tagFile : custom/legal-info.txt , tagName : License , userValue : https://creativecommons.org/publicdomain/zero/1.0/ } ] } Let's assume the hypothetical \"APTrust Demo System Workflow\" includes the following steps: Package all files according to our customized version of the APTrust BagIt profile. Validate the resulting bag. Upload the bag to our ingest bucket for the APTrust Demo system. Upload the bag to the S3 bucket in our local owncloud S3 service. Passing the JSON above to the DART command line application will result in the following: The file /path/to/some/document.pdf and the contents of the directories /path/to/first/directory and /path/to/second/directory will be packed into the data directory of a new BagIt bag. DART will create and populate all of the tag files required by the APTrust BagIt profile. It will use the default values saved in your locally customized version of the profile where possible, overriding the defaults with the bag-specific values supplied in the JSON. Note Note that certain BagIt tag values, such as Source-Organization, Contact-Email, etc. will not change from bag to bag, so it makes sense to set default values for them in your customized profile. Other values, such as bag title and description, will change for every bag, so it makes sense to set them in the JobParams JSON. DART will save the entire package to a file whose name matches the package name. DART will write the file into your bagging directory, which is usually a directory called .dart under your home directory. You can verify (and change) the name of your bagging directory by choosing App Settings from the DART menu and clicking on the setting called Bagging Directory . DART will verify the bag according to the APTrust BagIt profile (or whichever profile the Workflow specified). DART will upload the verified bag to APTrust's S3 ingest bucket. DART will upload the verified bag to your local ownCloud S3 bucket. See also: Workflows , Command Line Reference , Scripting with DART","title":"Job Params"},{"location":"users/workflows/job_params/#further-reading","text":"You'll find more detailed developer documentation for the JobParams object in our DART API documentation .","title":"Further Reading"}]}